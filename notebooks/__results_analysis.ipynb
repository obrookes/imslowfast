{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\n",
    "    \"model=rnn-encoder-decoder_w-negative_hidden-dim=256_nlayers=1_batch_size=256.npz\"\n",
    ")\n",
    "\n",
    "train_predictions = data[\"train_preds\"]\n",
    "train_targets = data[\"train_targets\"]\n",
    "train_masks = data[\"train_mask\"]\n",
    "\n",
    "val_predictions = data[\"val_preds\"]\n",
    "val_targets = data[\"val_targets\"]\n",
    "val_masks = data[\"val_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = pd.DataFrame(\n",
    "    {\n",
    "        \"val_targets\": list(val_targets[199]),\n",
    "        \"val_predictions\": list(val_predictions[199]),\n",
    "    }\n",
    ")\n",
    "train_results = pd.DataFrame(\n",
    "    {\n",
    "        \"train_targets\": list(train_targets[199]),\n",
    "        \"train_predictions\": list(train_predictions[199]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size), \"valid\") / window_size\n",
    "\n",
    "\n",
    "def generate_distinct_colors(n):\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"\",\n",
    "        [\n",
    "            \"blue\",\n",
    "            \"green\",\n",
    "            \"red\",\n",
    "            \"cyan\",\n",
    "            \"magenta\",\n",
    "            \"yellow\",\n",
    "            \"black\",\n",
    "            \"orange\",\n",
    "            \"purple\",\n",
    "            \"brown\",\n",
    "        ],\n",
    "    )\n",
    "    return [cmap(i / n) for i in range(n)]\n",
    "\n",
    "\n",
    "def plot_per_class_accuracy(\n",
    "    predictions,\n",
    "    targets,\n",
    "    masks,\n",
    "    class_names=None,\n",
    "    smoothing_window=1,\n",
    "    exclude_tokens=None,\n",
    "    split=None,\n",
    "):\n",
    "    E, N, S = predictions.shape\n",
    "    num_classes = np.max(targets) + 1  # Assuming class indices start from 0\n",
    "\n",
    "    # Use default class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "    elif len(class_names) != num_classes:\n",
    "        raise ValueError(\n",
    "            \"The number of class names must match the number of classes in the data.\"\n",
    "        )\n",
    "\n",
    "    # Create a mask for excluded tokens\n",
    "    if exclude_tokens is None:\n",
    "        exclude_tokens = []\n",
    "    exclude_mask = np.ones(num_classes, dtype=bool)\n",
    "    exclude_mask[exclude_tokens] = False\n",
    "\n",
    "    # Initialize array to store accuracies\n",
    "    accuracies = np.zeros((E, num_classes))\n",
    "\n",
    "    # Calculate accuracies for each epoch and class\n",
    "    for epoch in range(E):\n",
    "        for class_idx in range(num_classes):\n",
    "            if class_idx not in exclude_tokens:\n",
    "                class_mask = (targets[epoch] == class_idx) & masks[epoch]\n",
    "                correct = (predictions[epoch] == targets[epoch]) & class_mask\n",
    "                total = np.sum(class_mask)\n",
    "                if total > 0:\n",
    "                    accuracies[epoch, class_idx] = np.sum(correct) / total\n",
    "\n",
    "    # Generate distinct colors for each class\n",
    "    colors = generate_distinct_colors(num_classes - len(exclude_tokens))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    color_idx = 0\n",
    "    for class_idx in range(num_classes):\n",
    "        if class_idx not in exclude_tokens:\n",
    "            class_accuracies = accuracies[:, class_idx]\n",
    "\n",
    "            if smoothing_window > 1:\n",
    "                smoothed_accuracies = moving_average(class_accuracies, smoothing_window)\n",
    "                epochs = range(smoothing_window - 1, E)\n",
    "                plt.plot(\n",
    "                    epochs,\n",
    "                    smoothed_accuracies,\n",
    "                    label=class_names[class_idx],\n",
    "                    color=colors[color_idx],\n",
    "                )\n",
    "            else:\n",
    "                plt.plot(\n",
    "                    range(E),\n",
    "                    class_accuracies,\n",
    "                    label=class_names[class_idx],\n",
    "                    color=colors[color_idx],\n",
    "                )\n",
    "            color_idx += 1\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{split.capitalize()} Per-Class Accuracy Across Epochs\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_per_class_metric(\n",
    "    predictions,\n",
    "    targets,\n",
    "    masks,\n",
    "    epoch,\n",
    "    metric=\"accuracy\",\n",
    "    class_names=None,\n",
    "    exclude_tokens=[0, 15, 16],\n",
    "    return_average=False,\n",
    "):\n",
    "    E, N, S = predictions.shape\n",
    "    num_classes = np.max(targets) + 1  # Assuming class indices start from 0\n",
    "\n",
    "    # Use default class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "    elif len(class_names) != num_classes:\n",
    "        raise ValueError(\n",
    "            \"The number of class names must match the number of classes in the data.\"\n",
    "        )\n",
    "\n",
    "    # Initialize array to store metric values\n",
    "    metric_values = np.zeros(num_classes)\n",
    "\n",
    "    # Calculate metric for each class given epoch\n",
    "    for class_idx in range(num_classes):\n",
    "        if class_idx not in exclude_tokens:\n",
    "            class_mask = (targets[epoch] == class_idx) & masks[epoch]\n",
    "            true_positives = np.sum(\n",
    "                (predictions[epoch] == class_idx)\n",
    "                & (targets[epoch] == class_idx)\n",
    "                & masks[epoch]\n",
    "            )\n",
    "            false_positives = np.sum(\n",
    "                (predictions[epoch] == class_idx)\n",
    "                & (targets[epoch] != class_idx)\n",
    "                & masks[epoch]\n",
    "            )\n",
    "            false_negatives = np.sum(\n",
    "                (predictions[epoch] != class_idx)\n",
    "                & (targets[epoch] == class_idx)\n",
    "                & masks[epoch]\n",
    "            )\n",
    "\n",
    "            if metric == \"accuracy\":\n",
    "                total = np.sum(class_mask)\n",
    "                if total > 0:\n",
    "                    metric_values[class_idx] = true_positives / total\n",
    "            elif metric == \"precision\":\n",
    "                if true_positives + false_positives > 0:\n",
    "                    metric_values[class_idx] = true_positives / (\n",
    "                        true_positives + false_positives\n",
    "                    )\n",
    "            elif metric == \"recall\":\n",
    "                if true_positives + false_negatives > 0:\n",
    "                    metric_values[class_idx] = true_positives / (\n",
    "                        true_positives + false_negatives\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Invalid metric. Choose 'accuracy', 'precision', or 'recall'.\"\n",
    "                )\n",
    "\n",
    "    # Create results dictionary, excluding the specified tokens\n",
    "    results_dict = {\n",
    "        class_names[i]: metric_values[i]\n",
    "        for i in range(num_classes)\n",
    "        if i not in exclude_tokens\n",
    "    }\n",
    "\n",
    "    if return_average:\n",
    "        # Calculate average metric, excluding the specified tokens\n",
    "        avg_metric = np.mean(\n",
    "            [val for i, val in enumerate(metric_values) if i not in exclude_tokens]\n",
    "        )\n",
    "        return results_dict, avg_metric\n",
    "    else:\n",
    "        return results_dict\n",
    "\n",
    "\n",
    "def plot_per_class_metric(\n",
    "    predictions,\n",
    "    targets,\n",
    "    masks,\n",
    "    class_names=None,\n",
    "    exclude_tokens=[0, 15, 16],\n",
    "    metric=\"accuracy\",\n",
    "    smoothing_window=1,\n",
    "):\n",
    "    E, N, S = predictions.shape\n",
    "    num_classes = np.max(targets) + 1  # Assuming class indices start from 0\n",
    "\n",
    "    # Use default class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "    elif len(class_names) != num_classes:\n",
    "        raise ValueError(\n",
    "            \"The number of class names must match the number of classes in the data.\"\n",
    "        )\n",
    "\n",
    "    # Generate distinct colors for each class\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, num_classes - len(exclude_tokens)))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    color_idx = 0\n",
    "    for class_idx in range(num_classes):\n",
    "        if class_idx not in exclude_tokens:\n",
    "            class_metrics = [\n",
    "                calculate_per_class_metric(\n",
    "                    predictions,\n",
    "                    targets,\n",
    "                    masks,\n",
    "                    epoch,\n",
    "                    metric,\n",
    "                    class_names,\n",
    "                    exclude_tokens,\n",
    "                )[class_names[class_idx]]\n",
    "                for epoch in range(E)\n",
    "            ]\n",
    "\n",
    "            if smoothing_window > 1:\n",
    "                class_metrics = (\n",
    "                    np.convolve(class_metrics, np.ones(smoothing_window), \"valid\")\n",
    "                    / smoothing_window\n",
    "                )\n",
    "                epochs = range(smoothing_window - 1, E)\n",
    "            else:\n",
    "                epochs = range(E)\n",
    "\n",
    "            plt.plot(\n",
    "                epochs,\n",
    "                class_metrics,\n",
    "                label=class_names[class_idx],\n",
    "                color=colors[color_idx],\n",
    "            )\n",
    "            color_idx += 1\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.title(\n",
    "        f\"Per-Class {metric.capitalize()} Across Epochs (Smoothing Window: {smoothing_window})\"\n",
    "    )\n",
    "    plt.legend(loc=\"center right\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "with open(\"../data/behaviours.txt\", \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "exclude_tokens = [0, 15]  # Exclude SOS and PAD tokens\n",
    "\n",
    "# Plot with different smoothing windows\n",
    "smoothing_windows = [15]\n",
    "for window in smoothing_windows:\n",
    "    plot_per_class_metric(\n",
    "        train_predictions,\n",
    "        train_targets,\n",
    "        train_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"train\",\n",
    "        metric=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    plot_per_class_metric(\n",
    "        val_predictions,\n",
    "        val_targets,\n",
    "        val_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"val\",\n",
    "        metric=\"accuracy\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with different smoothing windows\n",
    "smoothing_windows = [15]\n",
    "for window in smoothing_windows:\n",
    "    plot_per_class_metric(\n",
    "        train_predictions,\n",
    "        train_targets,\n",
    "        train_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"train\",\n",
    "        metric=\"precision\",\n",
    "    )\n",
    "\n",
    "    plot_per_class_metric(\n",
    "        val_predictions,\n",
    "        val_targets,\n",
    "        val_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"val\",\n",
    "        metric=\"precision\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with different smoothing windows\n",
    "smoothing_windows = [15]\n",
    "for window in smoothing_windows:\n",
    "    plot_per_class_metric(\n",
    "        train_predictions,\n",
    "        train_targets,\n",
    "        train_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"train\",\n",
    "        metric=\"recall\",\n",
    "    )\n",
    "\n",
    "    plot_per_class_metric(\n",
    "        val_predictions,\n",
    "        val_targets,\n",
    "        val_masks,\n",
    "        class_names=[\"SOS\"] + behaviours + [\"PAD\"],\n",
    "        smoothing_window=window,\n",
    "        exclude_tokens=exclude_tokens,\n",
    "        # split=\"val\",\n",
    "        metric=\"recall\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_per_class_accuracy(\n",
    "    predictions,\n",
    "    targets,\n",
    "    masks,\n",
    "    epoch,\n",
    "    class_names=None,\n",
    "    exclude_tokens=[0, 15],\n",
    "    return_average=False,\n",
    "):\n",
    "    E, N, S = predictions.shape\n",
    "    num_classes = np.max(targets) + 1  # Assuming class indices start from 0\n",
    "\n",
    "    # Use default class names if not provided\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "    elif len(class_names) != num_classes:\n",
    "        raise ValueError(\n",
    "            \"The number of class names must match the number of classes in the data.\"\n",
    "        )\n",
    "\n",
    "    # Initialize array to store accuracies\n",
    "    accuracies = np.zeros(num_classes)\n",
    "\n",
    "    # Calculate accuracies for each class given epoch\n",
    "    for class_idx in range(num_classes):\n",
    "        if class_idx not in exclude_tokens:\n",
    "            class_mask = (targets[epoch] == class_idx) & masks[epoch]\n",
    "            correct = (predictions[epoch] == targets[epoch]) & class_mask\n",
    "            total = np.sum(class_mask)\n",
    "            if total > 0:\n",
    "                accuracies[class_idx] = np.sum(correct) / total\n",
    "\n",
    "    # Create results dictionary, excluding the specified tokens\n",
    "    results_dict = {\n",
    "        class_names[i]: accuracies[i]\n",
    "        for i in range(num_classes)\n",
    "        if i not in exclude_tokens\n",
    "    }\n",
    "\n",
    "    if return_average:\n",
    "        # Calculate average accuracy, excluding the specified tokens\n",
    "        avg_accuracy = np.mean(\n",
    "            [acc for i, acc in enumerate(accuracies) if i not in exclude_tokens]\n",
    "        )\n",
    "        return results_dict, avg_accuracy\n",
    "    else:\n",
    "        return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per_class_acc = calculate_per_class_accuracy(\n",
    "    train_predictions,\n",
    "    train_targets,\n",
    "    train_masks,\n",
    "    100,\n",
    "    class_names=[\"<sos>\"] + behaviours + [\"<pad>\"],\n",
    ")\n",
    "val_per_class_acc = calculate_per_class_accuracy(\n",
    "    val_predictions,\n",
    "    val_targets,\n",
    "    val_masks,\n",
    "    100,\n",
    "    class_names=[\"<sos>\"] + behaviours + [\"<pad>\"],\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.bar(\n",
    "    train_per_class_acc.keys(),\n",
    "    train_per_class_acc.values(),\n",
    "    color=\"blue\",\n",
    "    alpha=0.5,\n",
    "    label=\"Train\",\n",
    ")\n",
    "plt.bar(\n",
    "    val_per_class_acc.keys(),\n",
    "    val_per_class_acc.values(),\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    "    label=\"Validation\",\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Per-Class Accuracy at Epoch 200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequence Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_len(x):\n",
    "    count = 0\n",
    "    for elem in x:\n",
    "        if not elem == -1:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def get_acc_per_seq_len(predictions, targets, masks, partition, epoch):\n",
    "\n",
    "    target_df = pd.DataFrame(\n",
    "        {\n",
    "            \"targets\": list(targets[epoch]),\n",
    "            \"predictions\": list(predictions[epoch]),\n",
    "            \"masks\": list(masks[epoch]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Apply mask to predictions\n",
    "    target_df[\"masked_predictions\"] = target_df.apply(\n",
    "        lambda x: [\n",
    "            x[\"predictions\"][i] if x[\"masks\"][i] else -1\n",
    "            for i in range(len(x[\"predictions\"]))\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Calculate gt sequence lengths\n",
    "    target_df[\"gt_seq_len\"] = target_df[\"targets\"].apply(lambda x: get_seq_len(x))\n",
    "\n",
    "    # Calculate masked sequence lengths\n",
    "    target_df[\"masked_seq_len\"] = target_df[\"masked_predictions\"].apply(\n",
    "        lambda x: get_seq_len(x)\n",
    "    )\n",
    "\n",
    "    # Per sequence accuracy\n",
    "    target_df[\"seq_accuracy\"] = target_df.apply(\n",
    "        lambda x: np.mean(\n",
    "            [\n",
    "                x[\"targets\"][i] == x[\"masked_predictions\"][i]\n",
    "                for i in range(len(x[\"targets\"]))\n",
    "                if x[\"masks\"][i]\n",
    "            ]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # Calculate average accuracy per gt sequence_len\n",
    "    target_df.groupby(\"masked_seq_len\")[\"seq_accuracy\"].mean().plot(\n",
    "        kind=\"bar\", title=f\"Average Accuracy per GT Sequence Length ({partition})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_per_seq_len(train_predictions, train_targets, train_masks, \"train\", 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_acc_per_seq_len(val_predictions, val_targets, val_masks, \"val\", 199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_df(predictions, targets, masks, partition, epoch):\n",
    "    target_df = pd.DataFrame(\n",
    "        {\n",
    "            \"targets\": list(targets[epoch]),\n",
    "            \"predictions\": list(predictions[epoch]),\n",
    "            \"masks\": list(masks[epoch]),\n",
    "        }\n",
    "    )\n",
    "    return target_df\n",
    "\n",
    "\n",
    "def plot_class_distribution(df, elements, partition, class_names):\n",
    "    num_elements = len(elements)\n",
    "    num_cols = (\n",
    "        3  # You can change this value to adjust the number of columns in the grid\n",
    "    )\n",
    "    num_rows = (\n",
    "        num_elements + num_cols - 1\n",
    "    ) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6 * num_cols, 6 * num_rows))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "    for i, element in enumerate(elements):\n",
    "        ax = axes[i]\n",
    "        # Filter for padding elements\n",
    "        filtered_df = df[df[\"targets\"].apply(lambda x: x[element] != -1)]\n",
    "\n",
    "        # Plot the class distribution of the element\n",
    "        sns.histplot(\n",
    "            filtered_df[\"targets\"].apply(lambda x: x[element]),\n",
    "            bins=np.arange(len(class_names) + 1),\n",
    "            discrete=True,\n",
    "            color=\"blue\",\n",
    "            alpha=0.5,\n",
    "            label=\"Ground Truth\",\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # Put class names on the x-axis\n",
    "        ax.set_xticks(np.arange(len(class_names)))\n",
    "        ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "        ax.set_xlabel(\"Class\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"Class Distribution of Element {element} ({partition})\")\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_df = get_target_df(train_predictions, train_targets, train_masks, \"train\", 149)\n",
    "plot_class_distribution(tgt_df, [0, 1, 2], \"train\", [\"<sos>\"] + behaviours + [\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate per class accuracy for each element and plot the results\n",
    "def plot_per_class_accuracy_per_element(\n",
    "    predictions, targets, masks, partition, epoch, elements\n",
    "):\n",
    "\n",
    "    target_df = get_target_df(predictions, targets, masks, partition, epoch)\n",
    "\n",
    "    for i, element in enumerate(elements):\n",
    "        target_df[f\"{element}_element_pred\"] = target_df.apply(\n",
    "            lambda x: x[\"predictions\"][i] if x[\"masks\"][i] else np.nan, axis=1\n",
    "        )\n",
    "\n",
    "        target_df[f\"{element}_element_gt\"] = target_df[\"targets\"].apply(\n",
    "            lambda x: x[i] if x[i] != -1 else np.nan\n",
    "        )\n",
    "    # Generate subplots based on the number of elements\n",
    "    num_elements = len(elements)\n",
    "    num_cols = (\n",
    "        3  # You can change this value to adjust the number of columns in the grid\n",
    "    )\n",
    "    num_rows = (\n",
    "        num_elements + num_cols - 1\n",
    "    ) // num_cols  # Calculate the number of rows needed\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6 * num_cols, 6 * num_rows))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy iteration\n",
    "\n",
    "    for i, element in enumerate(elements):\n",
    "\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Filter for padding elements\n",
    "        filtered_df = target_df[target_df[f\"{element}_element_pred\"].notnull()]\n",
    "\n",
    "        # Convert predictions and targets to tensors\n",
    "        preds = torch.tensor(\n",
    "            filtered_df[f\"{element}_element_pred\"].values, dtype=torch.long\n",
    "        )\n",
    "        targets = torch.tensor(\n",
    "            filtered_df[f\"{element}_element_gt\"].values, dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # Calculate per class accuracy\n",
    "        from torchmetrics.functional import accuracy\n",
    "\n",
    "        try:\n",
    "            per_class_accuracy = accuracy(\n",
    "                preds=preds,\n",
    "                target=targets,\n",
    "                num_classes=len(behaviours) + 2,\n",
    "                average=None,\n",
    "            )\n",
    "        except:\n",
    "            raise ValueError(\n",
    "                \"The number of classes in the data does not match the number of classes in the class names.\"\n",
    "            )\n",
    "\n",
    "        # Replace NaN values with 0\n",
    "        per_class_accuracy[torch.isnan(per_class_accuracy)] = 0\n",
    "\n",
    "        # Average accuracy\n",
    "        avg_per_class_accuracy = per_class_accuracy.mean().item()\n",
    "\n",
    "        # Overall accuracy\n",
    "        from sklearn.metrics import accuracy_score\n",
    "\n",
    "        overall_accuracy = accuracy_score(\n",
    "            filtered_df[f\"{element}_element_gt\"], filtered_df[f\"{element}_element_pred\"]\n",
    "        )\n",
    "\n",
    "        # Plot the per class accuracy\n",
    "        pd.Series(per_class_accuracy).plot(kind=\"bar\", ax=ax)\n",
    "        ax.set_xlabel(\"Class\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(\n",
    "            f\"{partition.capitalize()} Per-Class Accuracy of {element.capitalize()} (Acc: {overall_accuracy:.2f}, C-Avg: {avg_per_class_accuracy:.2f})\"\n",
    "        )\n",
    "        # Put class names on the x-axis\n",
    "        ax.set_xticks(np.arange(len(behaviours) + 2))\n",
    "        ax.set_xticklabels([\"<sos>\"] + behaviours + [\"<pad>\"], rotation=45, ha=\"right\")\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [\"zero\", \"first\", \"second\", \"third\", \"fourth\", \"fifth\"]\n",
    "\n",
    "plot_per_class_accuracy_per_element(\n",
    "    train_predictions, train_targets, train_masks, \"train\", 199, elements\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [\"zero\", \"first\", \"second\", \"third\", \"fourth\", \"fifth\", \"sixth\"]\n",
    "\n",
    "plot_per_class_accuracy_per_element(\n",
    "    val_predictions, val_targets, val_masks, \"val\", 199, elements\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transition Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_transition_matrix(input_sequences, exclude_special_tokens=False):\n",
    "    # Get the number of unique elements (assuming elements are integers starting from 0)\n",
    "    num_classes = 16  # Includes SOS (0) and PAD (15)\n",
    "\n",
    "    # Initialize the transition count matrix\n",
    "    transition_counts = torch.zeros((num_classes, num_classes), dtype=torch.float)\n",
    "\n",
    "    # Count transitions\n",
    "    for sequence in input_sequences:\n",
    "        if len(sequence) == 1:\n",
    "            from_state = sequence[0].item()\n",
    "            to_state = sequence[0].item()\n",
    "            if not (\n",
    "                exclude_special_tokens\n",
    "                and (from_state in [0, 15] or to_state in [0, 15])\n",
    "            ):\n",
    "                transition_counts[from_state, to_state] += 1\n",
    "        else:\n",
    "            # Count transitions in this sequence\n",
    "            for i in range(len(sequence) - 1):\n",
    "                from_state = sequence[i].item()\n",
    "                to_state = sequence[i + 1].item()\n",
    "                if not (\n",
    "                    exclude_special_tokens\n",
    "                    and (from_state in [0, 15] or to_state in [0, 15])\n",
    "                ):\n",
    "                    transition_counts[from_state, to_state] += 1\n",
    "\n",
    "    # Normalize to get probabilities\n",
    "    row_sums = transition_counts.sum(dim=1, keepdim=True)\n",
    "    transition_matrix = transition_counts / row_sums\n",
    "\n",
    "    # Handle division by zero\n",
    "    transition_matrix = torch.nan_to_num(transition_matrix, nan=0.0)\n",
    "\n",
    "    if exclude_special_tokens:\n",
    "        # Remove rows and columns corresponding to SOS and PAD tokens\n",
    "        mask = torch.ones(num_classes, dtype=bool)\n",
    "        mask[0] = False  # SOS token\n",
    "        mask[15] = False  # PAD token\n",
    "        transition_matrix = transition_matrix[mask][:, mask]\n",
    "\n",
    "    return transition_matrix\n",
    "\n",
    "\n",
    "def transition_matrix_at_epoch(input_sequences, masks, epoch):\n",
    "    masked_sequences = []\n",
    "    for i, (p, m) in enumerate(zip(input_sequences[epoch], masks[epoch])):\n",
    "        masked_sequences.append(p[m])\n",
    "    return calculate_transition_matrix(masked_sequences, exclude_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt_transitions = transition_matrix_at_epoch(train_targets, train_masks, 199)\n",
    "train_pred_transitions = transition_matrix_at_epoch(train_predictions, train_masks, 199)\n",
    "val_gt_transitions = transition_matrix_at_epoch(val_targets, val_masks, 199)\n",
    "val_pred_transitions = transition_matrix_at_epoch(val_predictions, val_masks, 199)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(24, 24))\n",
    "sns.heatmap(\n",
    "    train_gt_transitions,\n",
    "    annot=True,\n",
    "    xticklabels=behaviours,\n",
    "    yticklabels=behaviours,\n",
    "    ax=ax[0][0],\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".3f\",\n",
    ")\n",
    "sns.heatmap(\n",
    "    train_pred_transitions,\n",
    "    annot=True,\n",
    "    xticklabels=behaviours,\n",
    "    yticklabels=behaviours,\n",
    "    ax=ax[0][1],\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".3f\",\n",
    ")\n",
    "sns.heatmap(\n",
    "    val_gt_transitions,\n",
    "    annot=True,\n",
    "    xticklabels=behaviours,\n",
    "    yticklabels=behaviours,\n",
    "    ax=ax[1][0],\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".3f\",\n",
    ")\n",
    "sns.heatmap(\n",
    "    val_pred_transitions,\n",
    "    annot=True,\n",
    "    xticklabels=behaviours,\n",
    "    yticklabels=behaviours,\n",
    "    ax=ax[1][1],\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".3f\",\n",
    ")\n",
    "ax[0][0].set_title(\"Train: Ground Truth Transition Matrix\")\n",
    "ax[0][1].set_title(\"Train: Predicted Transition Matrix\")\n",
    "ax[1][0].set_title(\"Val: Ground Truth Transition Matrix\")\n",
    "ax[1][1].set_title(\"Val: Predicted Transition Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition matrix over time\n",
    "def transition_matrix_over_time(input_sequences, masks, epochs):\n",
    "    transition_matrices = torch.zeros(len(epochs), len(behaviours), len(behaviours))\n",
    "    for e, epoch in enumerate(epochs):\n",
    "        masked_sequences = []\n",
    "        for i, (p, m) in enumerate(zip(input_sequences[epoch], masks[epoch])):\n",
    "            masked_sequences.append(p[m])\n",
    "        transition_matrices[e] = calculate_transition_matrix(\n",
    "            masked_sequences, exclude_special_tokens=True\n",
    "        )\n",
    "    return transition_matrices\n",
    "\n",
    "\n",
    "def plot_transition_matrices(transition_matrices, epochs):\n",
    "    # Create a grid of subplots with max 3 columns\n",
    "    num_plots = len(epochs)\n",
    "    num_cols = min(num_plots, 3)\n",
    "    num_rows = (num_plots - 1) // num_cols + 1\n",
    "    fig, ax = plt.subplots(num_rows, num_cols, figsize=(10 * num_cols, 10 * num_rows))\n",
    "\n",
    "    # Plot each transition matrix\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        row = i // num_cols\n",
    "        col = i % num_cols\n",
    "        sns.heatmap(\n",
    "            transition_matrices[i],\n",
    "            annot=True,\n",
    "            xticklabels=behaviours,\n",
    "            yticklabels=behaviours,\n",
    "            ax=ax[row][col],\n",
    "            cmap=\"Blues\",\n",
    "            fmt=\".2f\",\n",
    "        )\n",
    "        ax[row][col].set_title(f\"Epoch {epoch}\")\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for i in range(num_plots, num_rows * num_cols):\n",
    "        fig.delaxes(ax.flatten()[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [0, 19, 39, 59, 79, 99]\n",
    "\n",
    "train_transition_matrices = transition_matrix_over_time(\n",
    "    train_predictions, train_masks, epochs\n",
    ")\n",
    "\n",
    "plot_transition_matrices(train_transition_matrices, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transition_matrices = transition_matrix_over_time(\n",
    "    val_predictions, val_masks, epochs\n",
    ")\n",
    "plot_transition_matrices(val_transition_matrices, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
