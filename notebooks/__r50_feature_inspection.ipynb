{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import mmcv\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_f1_score,\n",
    "    multilabel_precision,\n",
    "    multilabel_recall,\n",
    ")\n",
    "\n",
    "from data_utils import results2df\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Slowfast imports\n",
    "from slowfast.models import build_model\n",
    "from slowfast.utils.parser import load_config, alt_parse_args\n",
    "from slowfast.datasets.loader import construct_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/configs/SLOW_8x8_R50_Local.yaml\"\n",
    "path_to_ckpt = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/checkpoint_epoch_00200.pyth\"\n",
    "\n",
    "args = alt_parse_args()[:-1]\n",
    "cfg = load_config(\n",
    "    args[0],\n",
    "    path_to_config=path_to_config,\n",
    ")\n",
    "checkpoint = torch.load(path_to_ckpt, map_location=\"cpu\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = model.head.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = construct_loader(cfg, \"test\")  # dataset = build_dataset(\"tap\", cfg, \"train\")\n",
    "sample = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels, index, time, meta = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map = model.s5(\n",
    "    model.s4(model.s3(model.s2(model.s1([inputs[0][1].unsqueeze(0)]))))\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frame_wise_features(feature_map, t):\n",
    "    spatially_pooled = F.adaptive_avg_pool3d(feature_map, (t, 1, 1))\n",
    "    frame_wise_features = torch.flatten(spatially_pooled, start_dim=2)\n",
    "    return frame_wise_features\n",
    "\n",
    "\n",
    "frame_wise_features = extract_frame_wise_features(feature_map, t=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frame-wise cosine similarity\n",
    "frame_wise_features = frame_wise_features.squeeze(0)\n",
    "frame_wise_features = frame_wise_features.T\n",
    "frame_wise_features = F.normalize(frame_wise_features, p=2, dim=1)\n",
    "frame_wise_cosine_similarity = torch.mm(frame_wise_features, frame_wise_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_level_features = F.adaptive_avg_pool3d(feature_map, (1, 1, 1))\n",
    "video_level_features = torch.flatten(video_level_features, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# sns.heatmap(frame_wise_cosine_similarity.detach().numpy(), cmap=\"viridis\", annot=True)\n",
    "# plt.title(\"Frame-wise cosine similarity\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_wise_logits = []\n",
    "for feat in frame_wise_features:\n",
    "    frame_wise_logits.append(torch.sigmoid(classifier(feat).detach()).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frame-wise logits as heatmap\n",
    "frame_wise_logits = np.array(frame_wise_logits)\n",
    "# plt.figure(figsize=(10, 15), dpi=300)\n",
    "# sns.heatmap(frame_wise_logits.T, cmap=\"viridis\", annot=True)\n",
    "# plt.title(\"Frame-wise logits\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_level_logits = torch.sigmoid(classifier(video_level_features)).detach().numpy()\n",
    "\n",
    "video_level_logits = np.array(video_level_logits)\n",
    "# plt.figure(figsize=(1, 10))\n",
    "# sns.heatmap(video_level_logits.T, cmap=\"viridis\", annot=True)\n",
    "# plt.title(\"Video-level logits\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original video\n",
    "video_path = \"/home/dl18206/Desktop/phd/data/panaf/panaf_sequence/36070505.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape frame[10] to 256x256\n",
    "frame = frames[10]\n",
    "frame = cv2.resize(frame, (256, 256))\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View frame\n",
    "plt.imshow(frame)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial\n",
    "\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h * w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_map = feature_map[:, :, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams = returnCAM(\n",
    "    spatial_map.detach(),\n",
    "    classifier.weight.detach().numpy(),\n",
    "    torch.linspace(0, 13, steps=14).int(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render the CAM and output\n",
    "height, width, _ = frame.shape\n",
    "heatmap = cv2.applyColorMap(cv2.resize(cams[10], (width, height)), cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + frame * 0.5\n",
    "cv2.imwrite(\"CAM.jpg\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
