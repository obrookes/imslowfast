{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_average_precision,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load annotations and results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name\n",
    "model_name = \"slow_r50-w-negatives\"\n",
    "folder_path = \"../dataset/results/\"\n",
    "metadata_file = \"../dataset/metadata/metadata.csv\"\n",
    "behavioural_labels_file = \"../dataset/metadata/behaviours.txt\"\n",
    "segements_file = \"../dataset/metadata/segements.txt\"\n",
    "\n",
    "# list all result files in the folder which end with .pkl and contain the model name\n",
    "result_info = {}\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".pkl\") and model_name in file:\n",
    "        is_kinetics = False\n",
    "\n",
    "        if \"-kinetics\" not in file:\n",
    "            epoch = file.split(\"_\")[-2].split(\"=\")[1]\n",
    "        else:\n",
    "            is_kinetics = True\n",
    "\n",
    "            epoch = file.split(\"_\")[-2].split(\"=\")[1].split(\"-\")[0]\n",
    "\n",
    "        # get the split from the file name\n",
    "        split = file.split(\"=\")[-1].split(\".\")[0]\n",
    "\n",
    "        # add the file to the dictionary\n",
    "        # add model to the dictionary\n",
    "        if model_name not in result_info:\n",
    "            result_info[model_name] = {}\n",
    "        # add epoch to the dictionary\n",
    "        if epoch not in result_info[model_name]:\n",
    "            result_info[model_name][epoch] = {}\n",
    "        if split not in result_info[model_name][epoch]:\n",
    "            result_info[model_name][epoch][split] = {}\n",
    "        result_info[model_name][epoch][split] = {\n",
    "            \"file_path\": os.path.join(folder_path, file),\n",
    "            \"is_kinetics\": is_kinetics,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'slow_r50-w-negatives': {'100': {'val': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=100_split=val.pkl',\n",
       "    'is_kinetics': False},\n",
       "   'train': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=100_split=train.pkl',\n",
       "    'is_kinetics': False}},\n",
       "  '200': {'train': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=200_split=train.pkl',\n",
       "    'is_kinetics': False},\n",
       "   'val': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=200_split=val.pkl',\n",
       "    'is_kinetics': False}},\n",
       "  '0': {'train': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=0-kinetics_split=train.pkl',\n",
       "    'is_kinetics': True},\n",
       "   'val': {'file_path': '../dataset/results/model=slow_r50-w-negatives_e=0-kinetics_split=val.pkl',\n",
       "    'is_kinetics': True}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "with open(behavioural_labels_file, \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segements_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]\n",
    "\n",
    "\n",
    "def read_files(model_results, epoch):\n",
    "    with open(model_results[epoch][\"train\"][\"file_path\"], \"rb\") as f:\n",
    "        train_data = pkl.load(f)\n",
    "\n",
    "    with open(model_results[epoch][\"val\"][\"file_path\"], \"rb\") as f:\n",
    "        val_data = pkl.load(f)\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n",
    "def results2df(train_data, val_data, metadata_df):\n",
    "    # Process subclips\n",
    "    subclips = []\n",
    "    for i, split in enumerate([train_data, val_data]):\n",
    "        for name, pred, feat, label in zip(\n",
    "            split[\"names\"], split[\"preds\"], split[\"feats\"], split[\"labels\"]\n",
    "        ):\n",
    "            subclips.append(\n",
    "                {\n",
    "                    \"name\": name,\n",
    "                    \"split\": i,\n",
    "                    \"pred\": pred,\n",
    "                    \"feat\": feat,\n",
    "                    \"negative\": True if sum(label) == 0 else False,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(subclips, columns=[\"name\", \"split\", \"pred\", \"feat\", \"negative\"])\n",
    "\n",
    "    df[\"split\"] = df.split.map({0: \"train\", 1: \"val\"})\n",
    "    df = df.merge(metadata_df, how=\"left\", left_on=\"name\", right_on=\"subject_id\")\n",
    "\n",
    "    # Apply sigmoid to predictions\n",
    "    df[\"pred\"] = df.pred.apply(lambda x: torch.sigmoid(torch.tensor(x)))\n",
    "\n",
    "    # Convert label from str to int\n",
    "    df.label = df.label.apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "\n",
    "    # Add negative\n",
    "    df[\"negative\"] = df.label.apply(lambda x: sum(x) == 0)\n",
    "\n",
    "    # Add global location count to dataframe\n",
    "    df[\"location_count\"] = df.utm.map(df.utm.value_counts())\n",
    "\n",
    "    # Return train and val dataframes\n",
    "    train_df = df[df.split == \"train\"]\n",
    "    val_df = df[df.split == \"val\"]\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def print_per_segement_performance(map, segment, show_per_class=False):\n",
    "    res = []\n",
    "    for i, (b, s) in enumerate(zip(map, segments)):\n",
    "        if s == segment:\n",
    "            res.append({behaviours[i]: b})\n",
    "    agg_values = []\n",
    "    for r in res:\n",
    "        for _, value in r.items():\n",
    "            agg_values.append(value)\n",
    "    # if show_per_class:\n",
    "    #    print(f\"{segment}: {np.mean(agg_values):.2f} {res}\")\n",
    "    # else:\n",
    "    #    print(f\"{segment}: {np.mean(agg_values):.2f}\")\n",
    "\n",
    "    if show_per_class:\n",
    "        return {\n",
    "            segment: {\n",
    "                \"mean\": np.round(np.mean(agg_values), 2),\n",
    "                \"values\": res,\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            segment: {\n",
    "                \"mean\": np.round(np.mean(agg_values), 2),\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, round_to=2):\n",
    "    # Train performance\n",
    "    map = multilabel_average_precision(\n",
    "        torch.tensor(np.stack(df[\"pred\"])),\n",
    "        torch.tensor(np.stack(df[\"label\"])),\n",
    "        num_labels=14,\n",
    "        average=\"none\",\n",
    "    )\n",
    "    map_head = print_per_segement_performance(map, \"head\")\n",
    "    map_tail = print_per_segement_performance(map, \"tail\")\n",
    "    map_fs = print_per_segement_performance(map, \"few_shot\")\n",
    "\n",
    "    map_head = round(float(map_head[\"head\"][\"mean\"]), round_to)\n",
    "    map_tail = round(float(map_tail[\"tail\"][\"mean\"]), round_to)\n",
    "    map_fs = round(float(map_fs[\"few_shot\"][\"mean\"]), round_to)\n",
    "\n",
    "    avg_map = round(map.mean().item(), round_to)\n",
    "\n",
    "    return avg_map, map_head, map_tail, map_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"results.csv\"\n",
    "\n",
    "for m in result_info:\n",
    "    for epoch in result_info[m]:\n",
    "        # print(f\"Loading results for model: {m}, epoch: {epoch}\")\n",
    "        train_data, val_data = read_files(result_info[model_name], epoch)\n",
    "        train_df, val_df = results2df(train_data, val_data, metadata_df)\n",
    "\n",
    "        train_map, train_map_head, map_tail, map_fs = calculate_metrics(train_df)\n",
    "        val_map, val_map_head, val_map_tail, val_map_fs = calculate_metrics(val_df)\n",
    "\n",
    "        # Write results to file # with columns: model, epoch, train_map, train_map_head, train_map_tail, train_map_fs, val_map, val_map_head, val_map_tail, val_map_fs\n",
    "        with open(result_file, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{m},{epoch},{train_map},{train_map_head},{map_tail},{map_fs},{val_map},{val_map_head},{val_map_tail},{val_map_fs}\\n\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
