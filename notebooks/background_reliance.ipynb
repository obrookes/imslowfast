{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import scienceplots\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plot_utils import plot_behavior_distribution\n",
    "from data_utils import (\n",
    "    results2df,\n",
    ")\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_average_precision,\n",
    "    multilabel_f1_score,\n",
    ")\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "plt.rcParams.update({\"font.family\": \"Times New Roman\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/metadata_with_nv.csv\"\n",
    "behaviours_file = \"../dataset/metadata/behaviours.txt\"\n",
    "segments_file = \"../dataset/metadata/segments.txt\"\n",
    "\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "with open(behaviours_file, \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segments_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]\n",
    "\n",
    "dummy_aps = [\n",
    "    0.0235,\n",
    "    0.0531,\n",
    "    0.1467,\n",
    "    0.1292,\n",
    "    0.0346,\n",
    "    0.2582,\n",
    "    0.0776,\n",
    "    0.1038,\n",
    "    0.0155,\n",
    "    0.0115,\n",
    "    0.4553,\n",
    "    0.1002,\n",
    "    0.5724,\n",
    "    0.0563,\n",
    "]\n",
    "\n",
    "\n",
    "exc_dummy_aps = [\n",
    "    0.0206,\n",
    "    0.0453,\n",
    "    0.1432,\n",
    "    0.1658,\n",
    "    0.0227,\n",
    "    0.2533,\n",
    "    0.0618,\n",
    "    0.1267,\n",
    "    0.0175,\n",
    "    0.0062,\n",
    "    0.4027,\n",
    "    0.1432,\n",
    "    0.62,\n",
    "    0.0494,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Meta-location label dist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(35, 20))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# All metadata_df[\"location_metadata\"].unique()\n",
    "# Fruit [x for x in metadata_df.location_metadata.unique() if 'fruit' in x]\n",
    "\n",
    "for i, ml in enumerate(\n",
    "    [x for x in metadata_df.location_metadata.unique() if \"fruit\" in x]\n",
    "):\n",
    "    behavior_counts = np.sum(\n",
    "        metadata_df[metadata_df.location_metadata == ml][\"label\"].tolist(), axis=0\n",
    "    )\n",
    "    ax[i].bar(behaviours, behavior_counts)\n",
    "    ax[i].set_title(ml)\n",
    "    ax[i].set_xticks(behaviours)\n",
    "    ax[i].set_xticklabels(behaviours, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the behaviour distribution for the standard and exclusive datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_tr_df = pd.read_csv(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/exclusive_utm/train.csv\"\n",
    ")\n",
    "std_tr_df = pd.read_csv(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/train.csv\"\n",
    ")\n",
    "\n",
    "exc_tr_df.columns = [\"name\", \"name_bg\", \"label\", \"negative\", \"utm\"]\n",
    "exc_tr_df = exc_tr_df[[\"name\", \"label\"]]\n",
    "\n",
    "std_tr_df.columns = [\"name\", \"label\"]\n",
    "\n",
    "exc_tr_df[\"label\"] = exc_tr_df[\"label\"].apply(lambda x: ast.literal_eval(x))\n",
    "std_tr_df[\"label\"] = std_tr_df[\"label\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "exc_dist = (\n",
    "    plot_behavior_distribution(exc_tr_df, behaviours, \"percentage\", plot=False)\n",
    "    .sort_values(by=\"behavior\")\n",
    "    .percentage\n",
    ")\n",
    "std_dist = (\n",
    "    plot_behavior_distribution(std_tr_df, behaviours, \"percentage\", plot=False)\n",
    "    .sort_values(by=\"behavior\")\n",
    "    .percentage\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "# Assuming behaviours, exc_dist, and std_dist are defined\n",
    "bars1 = sns.barplot(\n",
    "    x=behaviours,\n",
    "    y=exc_dist,\n",
    "    color=\"red\",\n",
    "    label=\"Exclusive\",\n",
    "    alpha=0.5,\n",
    "    linewidth=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "bars2 = sns.barplot(\n",
    "    x=behaviours,\n",
    "    y=std_dist,\n",
    "    color=\"blue\",\n",
    "    label=\"Standard\",\n",
    "    alpha=0.5,\n",
    "    linewidth=0.5,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.xlabel(\"Behaviour\")\n",
    "plt.title(\"Behaviour distribution in standard and exclusive datasets\")\n",
    "\n",
    "# Calculate and display the differences\n",
    "for i, (exc, std) in enumerate(zip(exc_dist, std_dist)):\n",
    "    diff = exc - std\n",
    "    ax.text(i, max(exc, std), f\"{diff:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "# plt.savefig('behaviour_distribution.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, round_to=3, show_per_class=True):\n",
    "    map_values = multilabel_average_precision(\n",
    "        torch.tensor(np.stack(df[\"pred\"])),\n",
    "        torch.tensor(np.stack(df[\"label\"])),\n",
    "        num_labels=14,\n",
    "        average=\"none\",\n",
    "        # thresholds=200,\n",
    "    )\n",
    "    avg_map = round(map_values.mean().item(), round_to)\n",
    "    if show_per_class:\n",
    "        map_values_list = []\n",
    "        for v in map_values:\n",
    "            map_v = round(v.item(), round_to)\n",
    "            map_values_list.append(map_v)\n",
    "\n",
    "        return map_values_list\n",
    "    return avg_map\n",
    "\n",
    "\n",
    "def calculate_imbalance_measures(df):\n",
    "    counts = df[\"count\"]\n",
    "    total_samples = counts.sum()\n",
    "    scaling_factor = np.log(total_samples)\n",
    "\n",
    "    # 1. Gini coefficient\n",
    "    def gini(x):\n",
    "        x = np.sort(x)\n",
    "        index = np.arange(1, len(x) + 1)\n",
    "        return (np.sum((2 * index - len(x) - 1) * x)) / (len(x) * np.sum(x))\n",
    "\n",
    "    gini_coefficient = gini(counts)\n",
    "\n",
    "    # 2. Coefficient of variation\n",
    "    cv = counts.std() / counts.mean()\n",
    "\n",
    "    # 3. 80-20 rule (Pareto principle)\n",
    "    sorted_counts = counts.sort_values(ascending=False)\n",
    "    cumulative_sum = sorted_counts.cumsum()\n",
    "    percentile_80 = np.interp(\n",
    "        0.8 * total_samples, cumulative_sum, range(1, len(cumulative_sum) + 1)\n",
    "    )\n",
    "    pareto_ratio = percentile_80 / len(counts)\n",
    "\n",
    "    # 4. Entropy-based measure\n",
    "    probabilities = counts / total_samples\n",
    "    entropy = stats.entropy(probabilities)\n",
    "    max_entropy = np.log(len(counts))\n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    imbalance_score = 1 - normalized_entropy\n",
    "\n",
    "    return {\n",
    "        \"gini_coefficient\": gini_coefficient,\n",
    "        \"scaled_gini_coefficient\": gini_coefficient * scaling_factor,\n",
    "        \"coefficient_of_variation\": cv,\n",
    "        \"scaled_coefficient_of_variation\": cv * scaling_factor,\n",
    "        \"pareto_ratio\": pareto_ratio,\n",
    "        \"scaled_pareto_ratio\": pareto_ratio * scaling_factor,\n",
    "        \"imbalance_score\": imbalance_score,\n",
    "        \"scaled_imbalance_score\": imbalance_score * scaling_factor,\n",
    "        \"total_samples\": total_samples,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non specific train results (no split)\n",
    "train_df = pd.read_csv(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/train.csv\"\n",
    ")\n",
    "train_df.columns = [\"name\", \"label\"]\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\"\n",
    ")\n",
    "\n",
    "train_df[\"label\"] = train_df.label.apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results\"\n",
    "\n",
    "results_df = None\n",
    "\n",
    "# Get paths to all pickle files\n",
    "val_paths = []\n",
    "for root, dirs, files in os.walk(val_results):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):\n",
    "            val_paths.append(os.path.join(root, file))\n",
    "\n",
    "for val_path in val_paths:\n",
    "\n",
    "    col_name = val_path.split(\"/\")[-2]\n",
    "\n",
    "    with open(\n",
    "        val_path,\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        val_data = pkl.load(f)\n",
    "\n",
    "    _, val_df = results2df(val_data, val_data, metadata_df, right_on=\"subject_id_fg\")\n",
    "\n",
    "    if results_df is None:\n",
    "        results_df = pd.DataFrame(\n",
    "            {\n",
    "                \"behaviour\": behaviours,\n",
    "                \"segment\": segments,\n",
    "                f\"{col_name}\": calculate_metrics(val_df),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        results_df[col_name] = calculate_metrics(val_df)\n",
    "\n",
    "results_df[\"dummy_aps\"] = dummy_aps\n",
    "results_df[\"exc_dummy_aps\"] = exc_dummy_aps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline vs. Background-only on Standard Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"dummy_aps\",\n",
    "        \"model=slow_r50_e300_bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "res1.rename(\n",
    "    columns={\n",
    "        \"model=slow_r50_e300_bg-only\": \"bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\": \"baseline\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "res1[\"bg_dummy_diff\"] = res1[\"bg-only\"] - res1[\"dummy_aps\"]\n",
    "res1[\"bl_bg_diff\"] = res1[\"baseline\"] - res1[\"bg-only\"]\n",
    "\n",
    "res1[\"bg_dummy_rel_diff\"] = res1[\"bg-only\"] / res1[\"dummy_aps\"]\n",
    "res1[\"bl_bg_rel_diff\"] = res1[\"baseline\"] / res1[\"bg-only\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"exc_dummy_aps\",\n",
    "        \"model=slow_r50_exclusive_utms_bg_only\",\n",
    "        \"model=slow_r50_exclusive_utms_fg_only\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "res2.rename(\n",
    "    columns={\n",
    "        \"model=slow_r50_exclusive_utms_bg_only\": \"bg-only_exc_utm\",\n",
    "        \"model=slow_r50_exclusive_utms_fg_only\": \"baseline_exc_utm\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = []\n",
    "for s in res1.segment.unique():\n",
    "    abs_diff = res1[res1.segment == s][\"bg_dummy_diff\"].mean()\n",
    "    rel_diff = res1[res1.segment == s][\"bg_dummy_rel_diff\"].mean()\n",
    "    abs_diff1 = res1[res1.segment == s][\"bl_bg_diff\"].mean()\n",
    "    rel_diff1 = res1[res1.segment == s][\"bl_bg_rel_diff\"].mean()\n",
    "\n",
    "    dummy_perfomance = res1[res1.segment == s][\"dummy_aps\"].mean()\n",
    "    background_performance = res1[res1.segment == s][\"bg-only\"].mean()\n",
    "    baseline_performance = res1[res1.segment == s][\"baseline\"].mean()\n",
    "\n",
    "    # Multiply all by 100 to get percentage\n",
    "    abs_diff *= 100\n",
    "    abs_diff1 *= 100\n",
    "\n",
    "    diff1.append(\n",
    "        {\n",
    "            \"segment\": s,\n",
    "            \"dummy_aps\": dummy_perfomance,\n",
    "            \"bg-only\": background_performance,\n",
    "            \"baseline\": baseline_performance,\n",
    "            \"bg_dummy_diff\": round(abs_diff, 2),\n",
    "            \"bg_dummy_rel_diff\": rel_diff,\n",
    "            \"bl_bg_diff\": abs_diff1,\n",
    "            \"bl_bg_rel_diff\": rel_diff1,\n",
    "        }\n",
    "    )\n",
    "diff1 = pd.DataFrame(diff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2 = []\n",
    "for s in res2.segment.unique():\n",
    "    abs_diff = res2[res2.segment == s][\"bg-only_exc_utm\"].mean()\n",
    "    rel_diff = res2[res2.segment == s][\"bg-only_exc_utm\"].mean()\n",
    "    abs_diff1 = res2[res2.segment == s][\"baseline_exc_utm\"].mean()\n",
    "    rel_diff1 = res2[res2.segment == s][\"baseline_exc_utm\"].mean()\n",
    "\n",
    "    dummy_perfomance = res2[res2.segment == s][\"exc_dummy_aps\"].mean()\n",
    "    background_performance = res2[res2.segment == s][\"bg-only_exc_utm\"].mean()\n",
    "    baseline_performance = res2[res2.segment == s][\"baseline_exc_utm\"].mean()\n",
    "\n",
    "    # Multiply all by 100 to get percentage\n",
    "    abs_diff *= 100\n",
    "    abs_diff1 *= 100\n",
    "\n",
    "    diff2.append(\n",
    "        {\n",
    "            \"segment\": s,\n",
    "            \"dummy_aps\": dummy_perfomance,\n",
    "            \"bg-only\": background_performance,\n",
    "            \"baseline\": baseline_performance,\n",
    "            \"bg_dummy_diff\": round(abs_diff, 2),\n",
    "            \"bg_dummy_rel_diff\": rel_diff,\n",
    "            \"bl_bg_diff\": abs_diff1,\n",
    "            \"bl_bg_rel_diff\": rel_diff1,\n",
    "        }\n",
    "    )\n",
    "diff2 = pd.DataFrame(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1[[\"segment\", \"dummy_aps\", \"bg-only\", \"baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1[[\"segment\", \"bg_dummy_diff\", \"bl_bg_diff\", \"bg_dummy_rel_diff\", \"bl_bg_rel_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"dummy_aps\",\n",
    "        \"bg-only\",\n",
    "        \"baseline\",\n",
    "    ]\n",
    "].plot(\n",
    "    x=\"behaviour\",\n",
    "    y=[\n",
    "        \"dummy_aps\",\n",
    "        \"bg-only\",\n",
    "        \"baseline\",\n",
    "    ],\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Average Precision per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"exc_dummy_aps\",\n",
    "        \"model=slow_r50_exclusive_utms_bg_only\",\n",
    "        \"model=slow_r50_exclusive_utms_fg_only\",\n",
    "    ]\n",
    "].plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 5),\n",
    "    rot=45,\n",
    "    title=\"Average Precision per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_results_df = results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"dummy_aps\",\n",
    "        \"model=slow_r50_e300_bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "bg_results_df[\"dummy_bg_diff\"] = (\n",
    "    bg_results_df[\"model=slow_r50_e300_bg-only\"] - bg_results_df[\"dummy_aps\"]\n",
    ")\n",
    "bg_results_df[\"dummy_bg_rel_diff\"] = (\n",
    "    bg_results_df[\"model=slow_r50_e300_bg-only\"] / bg_results_df[\"dummy_aps\"]\n",
    ")\n",
    "\n",
    "\n",
    "bg_results_df[\"baseline_bg_diff\"] = (\n",
    "    bg_results_df[\"model=slow_r50_e200_baseline_results\"]\n",
    "    - bg_results_df[\"model=slow_r50_e300_bg-only\"]\n",
    ")\n",
    "bg_results_df[\"baseline_bg_rel_diff\"] = (\n",
    "    bg_results_df[\"model=slow_r50_e300_bg-only\"]\n",
    "    / bg_results_df[\"model=slow_r50_e200_baseline_results\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background model analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_model = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results/model=slow_r50_e300_bg-only/model=slow_r50_e300_bg-only_feats.pkl\"\n",
    "baseline_model = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results/model=slow_r50_e200_baseline_results/model=slow_r50_e200_baseline_results_feats.pkl\"\n",
    "\n",
    "with open(\n",
    "    bg_model,\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    bg_feats = pkl.load(f)\n",
    "\n",
    "with open(\n",
    "    baseline_model,\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    baseline_feats = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(bg_feats[\"names\"]),\n",
    "        \"pred\": list(bg_feats[\"preds\"].detach().cpu().numpy()),\n",
    "        \"label\": list(bg_feats[\"labels\"].detach().cpu().numpy()),\n",
    "    }\n",
    ").merge(metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\")\n",
    "\n",
    "bl_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(baseline_feats[\"names\"]),\n",
    "        \"pred\": list(baseline_feats[\"preds\"].detach().cpu().numpy()),\n",
    "        \"label\": list(baseline_feats[\"labels\"].detach().cpu().numpy()),\n",
    "    }\n",
    ").merge(metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\")\n",
    "\n",
    "bg_df[\"pred\"] = bg_df[\"pred\"].apply(\n",
    "    lambda x: torch.sigmoid(torch.tensor(x)).detach().cpu().numpy()\n",
    ")\n",
    "bl_df[\"pred\"] = bl_df[\"pred\"].apply(\n",
    "    lambda x: torch.sigmoid(torch.tensor(x)).detach().cpu().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does night vision affect the performance of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, round_to=3, show_per_class=True):\n",
    "    map_values = multilabel_average_precision(\n",
    "        torch.tensor(np.stack(df[\"pred\"])),\n",
    "        torch.tensor(np.stack(df[\"label\"])).long(),\n",
    "        num_labels=14,\n",
    "        average=\"none\",\n",
    "        # thresholds=200,\n",
    "    )\n",
    "    avg_map = round(map_values.mean().item(), round_to)\n",
    "    if show_per_class:\n",
    "        map_values_list = []\n",
    "        for v in map_values:\n",
    "            map_v = round(v.item(), round_to)\n",
    "            map_values_list.append(map_v)\n",
    "\n",
    "        return map_values_list\n",
    "    return avg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_nv_df = bg_df.merge(\n",
    "    metadata_df[[\"subject_id_fg\", \"night_vision\"]],\n",
    "    left_on=\"name\",\n",
    "    right_on=\"subject_id_fg\",\n",
    ")\n",
    "\n",
    "bl_nv_df = bl_df.merge(\n",
    "    metadata_df[[\"subject_id_fg\", \"night_vision\"]],\n",
    "    left_on=\"name\",\n",
    "    right_on=\"subject_id_fg\",\n",
    ")\n",
    "\n",
    "bg_nv_result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"night_vision\": calculate_metrics(bg_nv_df[bg_nv_df[\"night_vision\"]]),\n",
    "        \"no_night_vision\": calculate_metrics(bg_nv_df[~bg_nv_df[\"night_vision\"]]),\n",
    "    }\n",
    ")\n",
    "\n",
    "bl_nv_result_df = pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"night_vision\": calculate_metrics(bl_nv_df[bl_nv_df[\"night_vision\"]]),\n",
    "        \"no_night_vision\": calculate_metrics(bl_nv_df[~bl_nv_df[\"night_vision\"]]),\n",
    "    }\n",
    ")\n",
    "\n",
    "bg_nv_result_df[\"nv_diff\"] = (\n",
    "    bg_nv_result_df[\"night_vision\"] - bg_nv_result_df[\"no_night_vision\"]\n",
    ")\n",
    "bl_nv_result_df[\"nv_diff\"] = (\n",
    "    bl_nv_result_df[\"night_vision\"] - bl_nv_result_df[\"no_night_vision\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_nv_result_df.sort_values(\"nv_diff\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_nv_result_df.sort_values(\"nv_diff\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"bg_only\": bg_nv_result_df.night_vision,\n",
    "        \"baseline\": bl_nv_result_df.night_vision,\n",
    "    }\n",
    ").plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 5),\n",
    "    rot=45,\n",
    "    title=\"Average Precision per behaviour on night vision samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"bg_only\": bg_nv_result_df.no_night_vision,\n",
    "        \"baseline\": bl_nv_result_df.no_night_vision,\n",
    "    }\n",
    ").plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 5),\n",
    "    rot=45,\n",
    "    title=\"Average Precision per behaviour on daytime samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"bg_only_nv\": bg_nv_result_df.night_vision,\n",
    "        \"bg_only_day\": bg_nv_result_df.no_night_vision,\n",
    "        \"baseline_nv\": bl_nv_result_df.night_vision,\n",
    "        \"baseline_day\": bl_nv_result_df.no_night_vision,\n",
    "    }\n",
    ").plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 5),\n",
    "    rot=45,\n",
    "    title=\"Average Precision per behaviour on night vision samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\"label\"] = metadata_df[\"label\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(\n",
    "    metadata_df[metadata_df.night_vision],\n",
    "    behaviours,\n",
    "    dpi=100,\n",
    "    title=\"Night Vision Samples\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(\n",
    "    metadata_df[~metadata_df.night_vision], behaviours, dpi=100, title=\"Daytime Samples\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which samples does the model predict tool use for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_cls(x, cls, thresh):\n",
    "    idx = behaviours.index(cls)\n",
    "    l = True if x[\"label\"][idx] == 1.0 else False\n",
    "    p = True if x[\"pred\"][idx] >= thresh else False\n",
    "    return l and p\n",
    "\n",
    "\n",
    "def get_pred_only(x, cls, thresh):\n",
    "    idx = behaviours.index(cls)\n",
    "    p = True if x[\"pred\"][idx] >= thresh else False\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = None\n",
    "\n",
    "# Create thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for t in thresholds:\n",
    "\n",
    "    store = []\n",
    "\n",
    "    # Here, we define correct as the number of samples where the model predicts tool use > 0.5 and the label is 1.0\n",
    "    for b in behaviours:\n",
    "        beh, inter, diff, bgc, blc = [], [], [], [], []\n",
    "\n",
    "        bg_correct = bg_df[\n",
    "            bg_df.apply(lambda x: get_pred_and_cls(x, b, t), axis=1)\n",
    "        ].name.values\n",
    "\n",
    "        bl_correct = bl_df[\n",
    "            bl_df.apply(lambda x: get_pred_and_cls(x, b, t), axis=1)\n",
    "        ].name.values\n",
    "\n",
    "        beh.append(b)\n",
    "        inter.append(len(set(bg_correct).intersection(set(bl_correct))))\n",
    "        diff.append(len(set(bg_correct).difference(set(bl_correct))))\n",
    "        bgc.append(len(bg_correct))\n",
    "        blc.append(len(bl_correct))\n",
    "\n",
    "        try:\n",
    "            intersection_ratio = inter[0] / (inter[0] + diff[0])\n",
    "        except ZeroDivisionError:\n",
    "            intersection_ratio = 0\n",
    "\n",
    "        try:\n",
    "            diff_ratio = diff[0] / (inter[0] + diff[0])\n",
    "        except ZeroDivisionError:\n",
    "            diff_ratio = 1\n",
    "\n",
    "        sample = {\n",
    "            \"behaviour\": beh[0],\n",
    "            f\"inter_ratio@{round(t,1)}\": intersection_ratio,\n",
    "            f\"diff_ratio@{round(t,1)}\": diff_ratio,\n",
    "            # f\"inter@{round(t,1)}\": inter[0],\n",
    "            # f\"diff@{round(t,1)}\": diff[0],\n",
    "            # f\"bg_correct@{round(t,1)}\": bgc[0],\n",
    "            # f\"bl_correct@{round(t,1)}\": blc[0],\n",
    "        }\n",
    "\n",
    "        store.append(sample)\n",
    "\n",
    "    if inter_df is None:\n",
    "        inter_df = pd.DataFrame(store)\n",
    "    else:\n",
    "        inter_df = inter_df.merge(pd.DataFrame(store), on=\"behaviour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.rename(\n",
    "    columns={\n",
    "        \"model=slow_r50_e300_bg-only\": \"bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\": \"baseline\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Cam Locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1[res1.columns[:5]].sort_values(\"bg-only\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1[res1.columns[:5]].plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Average Precision per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1[[\"dummy_aps\", \"bg-only\", \"baseline\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1[[\"segment\", \"dummy_aps\", \"bg-only\", \"baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1[[\"segment\", \"bg_dummy_diff\", \"bl_bg_diff\", \"bg_dummy_rel_diff\", \"bl_bg_rel_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"dummy_aps\",\n",
    "        \"bg-only\",\n",
    "        \"baseline\",\n",
    "    ]\n",
    "].plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Average Precision per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.sort_values(\"inter_ratio@0.1\", ascending=False)[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"inter_ratio@0.1\",\n",
    "        \"diff_ratio@0.1\",\n",
    "        \"inter_ratio@0.5\",\n",
    "        \"diff_ratio@0.5\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.sort_values(\"inter_ratio@0.2\", ascending=False)[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"inter_ratio@0.2\",\n",
    "        \"diff_ratio@0.2\",\n",
    "    ]\n",
    "].plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Intersection and Difference Ratios per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.sort_values(\"inter_ratio@0.5\", ascending=False)[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"inter_ratio@0.5\",\n",
    "        \"diff_ratio@0.5\",\n",
    "    ]\n",
    "].plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Intersection and Difference Ratios per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclusive Cam Locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.plot(\n",
    "    x=\"behaviour\",\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Average Precision per behaviour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2[res2.columns[2:]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2[[\"segment\", \"dummy_aps\", \"bg-only\", \"baseline\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff2[[\"segment\", \"bg_dummy_diff\", \"bl_bg_diff\", \"bg_dummy_rel_diff\", \"bl_bg_rel_diff\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_loc_count = []\n",
    "for b in behaviours:\n",
    "    utm_df = (\n",
    "        train_df[train_df.label.apply(lambda x: x[behaviours.index(b)] == 1)]\n",
    "        .utm.value_counts()\n",
    "        .reset_index()\n",
    "    )\n",
    "    cam_loc_count.append(utm_df.utm.nunique())\n",
    "\n",
    "correct_df = pd.DataFrame(store)\n",
    "correct_df[\"cam_loc_count\"] = cam_loc_count\n",
    "correct_df[\"dummy\"] = bg_results_df.dummy_aps\n",
    "correct_df[\"bg_only\"] = bg_results_df[\"model=slow_r50_e300_bg-only\"]\n",
    "correct_df[\"baseline\"] = bg_results_df[\"model=slow_r50_e200_baseline_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(\n",
    "    train_df[train_df.utm.isin(bg_df[bg_df.name.isin(bg_correct)].utm.unique())],\n",
    "    behavior_list=behaviours,\n",
    "    annot=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prevalence(df, cls):\n",
    "    # Iterate through rows and count the number of times cls is present\n",
    "    cls_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"label\"][behaviours.index(cls)] == 1:\n",
    "            cls_count += 1\n",
    "    return cls_count / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label distribution\n",
    "train_behavior_counts = np.sum(train_df[\"label\"].tolist(), axis=0)\n",
    "train_behavior_percentages = (train_behavior_counts / train_behavior_counts.sum()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing whether the distribution of camera locations is important...\n",
    "\n",
    "cam_dist_df = None\n",
    "\n",
    "# Create thresholds\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "for t in [0.75]:  # thresholds:\n",
    "\n",
    "    store = []\n",
    "\n",
    "    for b in behaviours:\n",
    "\n",
    "        head, tail, hc, tc = [], [], [], []\n",
    "\n",
    "        bg_correct = bg_df[\n",
    "            bg_df.apply(lambda x: get_pred_and_cls(x, b, t), axis=1)\n",
    "        ].name.values\n",
    "\n",
    "        pred_loc = bg_df[bg_df.name.isin(bg_correct)].utm.unique()\n",
    "\n",
    "        pred_loc_counts = (\n",
    "            bg_df[bg_df.name.isin(bg_correct)].utm.value_counts().reset_index()\n",
    "        )\n",
    "\n",
    "        b_df = train_df[\n",
    "            train_df.label.apply(\n",
    "                lambda x: True if x[behaviours.index(b)] == 1 else False\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Get label distribution\n",
    "        behavior_counts = np.sum(b_df[\"label\"].tolist(), axis=0)\n",
    "        behavior_percentages = (behavior_counts / behavior_counts.sum()) * 100\n",
    "\n",
    "        train_agg_loc_counts = (\n",
    "            train_df[\n",
    "                train_df.label.apply(\n",
    "                    lambda x: True if x[behaviours.index(b)] == 1 else False\n",
    "                )\n",
    "            ]\n",
    "            .utm.value_counts()\n",
    "            .reset_index()\n",
    "        )\n",
    "        # Calculate the total number of videos\n",
    "        total_videos = train_agg_loc_counts[\"count\"].sum()\n",
    "\n",
    "        # Sort locations by video count in descending order and calculate cumulative percentage\n",
    "        location_counts = train_agg_loc_counts.sort_values(\"count\", ascending=False)\n",
    "        location_counts[\"cumulative_count\"] = location_counts[\"count\"].cumsum()\n",
    "        location_counts[\"cumulative_percentage\"] = (\n",
    "            location_counts[\"cumulative_count\"] / total_videos * 100\n",
    "        )\n",
    "\n",
    "        p = 50\n",
    "        head_locs = location_counts[location_counts.cumulative_percentage <= 50]\n",
    "        tail_locs = location_counts[location_counts.cumulative_percentage > 50]\n",
    "\n",
    "        head_utms = head_locs[head_locs.utm.isin(pred_loc)].utm.values\n",
    "        tail_utms = tail_locs[tail_locs.utm.isin(pred_loc)].utm.values\n",
    "\n",
    "        head_prop = (\n",
    "            pred_loc_counts[pred_loc_counts.utm.isin(head_utms)][\"count\"].sum()\n",
    "            / pred_loc_counts[\"count\"].sum()\n",
    "        )\n",
    "        tail_prop = (\n",
    "            pred_loc_counts[pred_loc_counts.utm.isin(tail_utms)][\"count\"].sum()\n",
    "            / pred_loc_counts[\"count\"].sum()\n",
    "        )\n",
    "\n",
    "        head.append(head_prop)\n",
    "        tail.append(tail_prop)\n",
    "\n",
    "        hc.append(pred_loc_counts[pred_loc_counts.utm.isin(head_utms)][\"count\"].sum())\n",
    "        tc.append(pred_loc_counts[pred_loc_counts.utm.isin(tail_utms)][\"count\"].sum())\n",
    "\n",
    "        store.append(\n",
    "            {\n",
    "                \"behaviour\": b,\n",
    "                f\"global_dist\": train_behavior_percentages[behaviours.index(b)],\n",
    "                f\"per_cam_dist@{round(t,2)}\": behavior_percentages[behaviours.index(b)],\n",
    "                f\"per_cam_full_dist@{round(t,2)}\": behavior_percentages,\n",
    "                f\"locations@{round(t,2)}\": np.unique(pred_loc),\n",
    "                f\"len_locations@{round(t,2)}\": len(np.unique(pred_loc)),\n",
    "                f\"bg_correct@{round(t,2)}\": bg_correct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if cam_dist_df is None:\n",
    "        cam_dist_df = pd.DataFrame(store)\n",
    "    else:\n",
    "        cam_dist_df = cam_dist_df.merge(\n",
    "            pd.DataFrame(store), on=[\"behaviour\", \"global_dist\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot per_cam_full_dist@0.25\n",
    "cam_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\n",
    "    metadata_df.label.apply(lambda x: x[behaviours.index(\"tool_use\")] == 1)\n",
    "].location_metadata.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\n",
    "    metadata_df.label.apply(lambda x: x[behaviours.index(\"resting\")] == 1)\n",
    "].location_metadata.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\n",
    "    metadata_df.subject_id_fg.isin(\n",
    "        cam_dist_df[\"bg_correct@0.75\"][behaviours.index(\"tool_use\")]\n",
    "    )\n",
    "].time_hr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\n",
    "    metadata_df.subject_id_fg.isin(\n",
    "        cam_dist_df[\"bg_correct@0.75\"][behaviours.index(\"tool_use\")]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 7, figsize=(35, 20))\n",
    "ax = ax.flatten()\n",
    "for i, dist in enumerate(cam_dist_df[\"per_cam_full_dist@0.5\"].values):\n",
    "    # Flatten the axes\n",
    "    # Plot each dist as a bar\n",
    "    ax[i].bar(behaviours, dist)\n",
    "    ax[i].set_title(behaviours[i])\n",
    "    ax[i].set_xticks(behaviours)\n",
    "    ax[i].set_xticklabels(behaviours, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[\n",
    "    metadata_df.label.apply(\n",
    "        lambda x: True if x[behaviours.index(\"tool_use\")] == 1 else False\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tool use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_tu_correct = bg_df[\n",
    "    bg_df.apply(lambda x: get_pred_only(x, \"tool_use\", 0.5), axis=1)\n",
    "].name.values\n",
    "bg_tu_df = metadata_df[metadata_df.subject_id_fg.isin(bg_tu_correct)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_tu_df = metadata_df[\n",
    "    metadata_df.label.apply(\n",
    "        lambda x: ast.literal_eval(x)[behaviours.index(\"tool_use\")] == 1\n",
    "    )\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
