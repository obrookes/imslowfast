{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import torch\n",
    "import scienceplots\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plot_utils import plot_behavior_distribution\n",
    "from data_utils import (\n",
    "    results2df,\n",
    ")\n",
    "from plot_utils import plot_behavior_distribution\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_average_precision,\n",
    "    multilabel_f1_score,\n",
    ")\n",
    "from matplotlib.colors import rgb2hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/with_negative_pairing/new_metadata.csv\"\n",
    "behaviours_file = \"../dataset/metadata/behaviours.txt\"\n",
    "segments_file = \"../dataset/metadata/segments.txt\"\n",
    "\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "with open(behaviours_file, \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segments_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]\n",
    "\n",
    "dummy_aps = [\n",
    "    0.0235,\n",
    "    0.0531,\n",
    "    0.1467,\n",
    "    0.1292,\n",
    "    0.0346,\n",
    "    0.2582,\n",
    "    0.0776,\n",
    "    0.1038,\n",
    "    0.0155,\n",
    "    0.0115,\n",
    "    0.4553,\n",
    "    0.1002,\n",
    "    0.5724,\n",
    "    0.0563,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, round_to=3, show_per_class=True):\n",
    "    map_values = multilabel_average_precision(\n",
    "        torch.tensor(np.stack(df[\"pred\"])),\n",
    "        torch.tensor(np.stack(df[\"label\"])),\n",
    "        num_labels=14,\n",
    "        average=\"none\",\n",
    "        # thresholds=200,\n",
    "    )\n",
    "    avg_map = round(map_values.mean().item(), round_to)\n",
    "    if show_per_class:\n",
    "        map_values_list = []\n",
    "        for v in map_values:\n",
    "            map_v = round(v.item(), round_to)\n",
    "            map_values_list.append(map_v)\n",
    "\n",
    "        return map_values_list\n",
    "    return avg_map\n",
    "\n",
    "\n",
    "def calculate_imbalance_measures(df):\n",
    "    counts = df[\"count\"]\n",
    "    total_samples = counts.sum()\n",
    "    scaling_factor = np.log(total_samples)\n",
    "\n",
    "    # 1. Gini coefficient\n",
    "    def gini(x):\n",
    "        x = np.sort(x)\n",
    "        index = np.arange(1, len(x) + 1)\n",
    "        return (np.sum((2 * index - len(x) - 1) * x)) / (len(x) * np.sum(x))\n",
    "\n",
    "    gini_coefficient = gini(counts)\n",
    "\n",
    "    # 2. Coefficient of variation\n",
    "    cv = counts.std() / counts.mean()\n",
    "\n",
    "    # 3. 80-20 rule (Pareto principle)\n",
    "    sorted_counts = counts.sort_values(ascending=False)\n",
    "    cumulative_sum = sorted_counts.cumsum()\n",
    "    percentile_80 = np.interp(\n",
    "        0.8 * total_samples, cumulative_sum, range(1, len(cumulative_sum) + 1)\n",
    "    )\n",
    "    pareto_ratio = percentile_80 / len(counts)\n",
    "\n",
    "    # 4. Entropy-based measure\n",
    "    probabilities = counts / total_samples\n",
    "    entropy = stats.entropy(probabilities)\n",
    "    max_entropy = np.log(len(counts))\n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    imbalance_score = 1 - normalized_entropy\n",
    "\n",
    "    return {\n",
    "        \"gini_coefficient\": gini_coefficient,\n",
    "        \"scaled_gini_coefficient\": gini_coefficient * scaling_factor,\n",
    "        \"coefficient_of_variation\": cv,\n",
    "        \"scaled_coefficient_of_variation\": cv * scaling_factor,\n",
    "        \"pareto_ratio\": pareto_ratio,\n",
    "        \"scaled_pareto_ratio\": pareto_ratio * scaling_factor,\n",
    "        \"imbalance_score\": imbalance_score,\n",
    "        \"scaled_imbalance_score\": imbalance_score * scaling_factor,\n",
    "        \"total_samples\": total_samples,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non specific train results (no split)\n",
    "train_df = pd.read_csv(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/train.csv\"\n",
    ")\n",
    "train_df.columns = [\"name\", \"label\"]\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\"\n",
    ")\n",
    "\n",
    "train_df[\"label\"] = train_df.label.apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results\"\n",
    "\n",
    "results_df = None\n",
    "\n",
    "# Get paths to all pickle files\n",
    "val_paths = []\n",
    "for root, dirs, files in os.walk(val_results):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):\n",
    "            val_paths.append(os.path.join(root, file))\n",
    "\n",
    "for val_path in val_paths:\n",
    "\n",
    "    col_name = val_path.split(\"/\")[-2]\n",
    "\n",
    "    with open(\n",
    "        val_path,\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        val_data = pkl.load(f)\n",
    "\n",
    "    _, val_df = results2df(val_data, val_data, metadata_df, right_on=\"subject_id_fg\")\n",
    "\n",
    "    if results_df is None:\n",
    "        results_df = pd.DataFrame(\n",
    "            {\n",
    "                \"behaviour\": behaviours,\n",
    "                \"segment\": segments,\n",
    "                f\"{col_name}\": calculate_metrics(val_df),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        results_df[col_name] = calculate_metrics(val_df)\n",
    "\n",
    "results_df[\"dummy_aps\"] = dummy_aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_df = results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"segment\",\n",
    "        \"dummy_aps\",\n",
    "        \"model=slow_r50_e300_bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "bg_df[\"dummy_bg_diff\"] = bg_df[\"model=slow_r50_e300_bg-only\"] - bg_df[\"dummy_aps\"]\n",
    "bg_df[\"dummy_bg_rel_diff\"] = 1 - (\n",
    "    bg_df[\"dummy_aps\"] / bg_df[\"model=slow_r50_e300_bg-only\"]\n",
    ")\n",
    "\n",
    "\n",
    "bg_df[\"baseline_bg_diff\"] = (\n",
    "    bg_df[\"model=slow_r50_e200_baseline_results\"] - bg_df[\"model=slow_r50_e300_bg-only\"]\n",
    ")\n",
    "bg_df[\"baseline_bg_rel_diff\"] = 1 - (\n",
    "    bg_df[\"model=slow_r50_e300_bg-only\"] / bg_df[\"model=slow_r50_e200_baseline_results\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behaviour</th>\n",
       "      <th>segment</th>\n",
       "      <th>dummy_aps</th>\n",
       "      <th>model=slow_r50_e300_bg-only</th>\n",
       "      <th>model=slow_r50_e200_baseline_results</th>\n",
       "      <th>dummy_bg_diff</th>\n",
       "      <th>dummy_bg_rel_diff</th>\n",
       "      <th>baseline_bg_diff</th>\n",
       "      <th>baseline_bg_rel_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tool_use</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>display</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.842009</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.611012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggression</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.807377</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.701711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>climbing</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.733058</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.304598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>piloerection</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.723214</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feeding</td>\n",
       "      <td>head</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.4108</td>\n",
       "      <td>0.614051</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.203571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vocalisation</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.566923</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>camera_reaction</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>0.523701</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>object_carrying</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.1038</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.503349</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bipedal</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.452577</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.705167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>grooming</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.403077</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.383886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>resting</td>\n",
       "      <td>head</td>\n",
       "      <td>0.4553</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.1677</td>\n",
       "      <td>0.269181</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.193005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>playing</td>\n",
       "      <td>few_shot</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>travel</td>\n",
       "      <td>head</td>\n",
       "      <td>0.5724</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.082692</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.322476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          behaviour   segment  dummy_aps  model=slow_r50_e300_bg-only  \\\n",
       "11         tool_use      tail     0.1002                        0.637   \n",
       "4           display  few_shot     0.0346                        0.219   \n",
       "0        aggression  few_shot     0.0235                        0.122   \n",
       "3          climbing      tail     0.1292                        0.484   \n",
       "8      piloerection  few_shot     0.0155                        0.056   \n",
       "5           feeding      head     0.2582                        0.669   \n",
       "13     vocalisation      tail     0.0563                        0.130   \n",
       "2   camera_reaction      tail     0.1467                        0.308   \n",
       "7   object_carrying      tail     0.1038                        0.209   \n",
       "1           bipedal      tail     0.0531                        0.097   \n",
       "6          grooming      tail     0.0776                        0.130   \n",
       "10          resting      head     0.4553                        0.623   \n",
       "9           playing  few_shot     0.0115                        0.014   \n",
       "12           travel      head     0.5724                        0.624   \n",
       "\n",
       "    model=slow_r50_e200_baseline_results  dummy_bg_diff  dummy_bg_rel_diff  \\\n",
       "11                                 0.871         0.5368           0.842700   \n",
       "4                                  0.563         0.1844           0.842009   \n",
       "0                                  0.409         0.0985           0.807377   \n",
       "3                                  0.696         0.3548           0.733058   \n",
       "8                                  0.231         0.0405           0.723214   \n",
       "5                                  0.840         0.4108           0.614051   \n",
       "13                                 0.338         0.0737           0.566923   \n",
       "2                                  0.448         0.1613           0.523701   \n",
       "7                                  0.342         0.1052           0.503349   \n",
       "1                                  0.329         0.0439           0.452577   \n",
       "6                                  0.211         0.0524           0.403077   \n",
       "10                                 0.772         0.1677           0.269181   \n",
       "9                                  0.040         0.0025           0.178571   \n",
       "12                                 0.921         0.0516           0.082692   \n",
       "\n",
       "    baseline_bg_diff  baseline_bg_rel_diff  \n",
       "11             0.234              0.268657  \n",
       "4              0.344              0.611012  \n",
       "0              0.287              0.701711  \n",
       "3              0.212              0.304598  \n",
       "8              0.175              0.757576  \n",
       "5              0.171              0.203571  \n",
       "13             0.208              0.615385  \n",
       "2              0.140              0.312500  \n",
       "7              0.133              0.388889  \n",
       "1              0.232              0.705167  \n",
       "6              0.081              0.383886  \n",
       "10             0.149              0.193005  \n",
       "9              0.026              0.650000  \n",
       "12             0.297              0.322476  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_df.sort_values(by=[\"dummy_bg_rel_diff\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in bg_df.segment.unique():\n",
    "    print(s, bg_df[bg_df.segment == s][\"baseline_bg_diff\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_model = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results/model=slow_r50_e300_bg-only/model=slow_r50_e300_bg-only_feats.pkl\"\n",
    "baseline_model = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results/model=slow_r50_e200_baseline_results/model=slow_r50_e200_baseline_results_feats.pkl\"\n",
    "\n",
    "with open(\n",
    "    bg_model,\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    bg_feats = pkl.load(f)\n",
    "\n",
    "with open(\n",
    "    baseline_model,\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    baseline_feats = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(bg_feats[\"names\"]),\n",
    "        \"pred\": list(bg_feats[\"preds\"].detach().cpu().numpy()),\n",
    "        \"label\": list(bg_feats[\"labels\"].detach().cpu().numpy()),\n",
    "    }\n",
    ").merge(metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\")\n",
    "\n",
    "bl_df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": list(baseline_feats[\"names\"]),\n",
    "        \"pred\": list(baseline_feats[\"preds\"].detach().cpu().numpy()),\n",
    "        \"label\": list(baseline_feats[\"labels\"].detach().cpu().numpy()),\n",
    "    }\n",
    ").merge(metadata_df[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\")\n",
    "\n",
    "bg_df[\"pred\"] = bg_df[\"pred\"].apply(\n",
    "    lambda x: torch.sigmoid(torch.tensor(x)).detach().cpu().numpy()\n",
    ")\n",
    "bl_df[\"pred\"] = bl_df[\"pred\"].apply(\n",
    "    lambda x: torch.sigmoid(torch.tensor(x)).detach().cpu().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which samples does the model predict tool use for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_and_cls(x, cls, thresh):\n",
    "    idx = behaviours.index(cls)\n",
    "    l = True if x[\"label\"][idx] == 1.0 else False\n",
    "    p = True if x[\"pred\"][idx] >= thresh else False\n",
    "    return l and p\n",
    "\n",
    "\n",
    "def get_pred_only(x, cls, thresh):\n",
    "    idx = behaviours.index(cls)\n",
    "    p = True if x[\"pred\"][idx] >= thresh else False\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we define correct as the number of samples where the model predicts tool use > 0.5 and the label is 1.0\n",
    "bg_correct = bg_df[\n",
    "    bg_df.apply(lambda x: get_pred_and_cls(x, \"tool_use\", 0.5), axis=1)\n",
    "].name.values\n",
    "\n",
    "bl_correct = bl_df[\n",
    "    bl_df.apply(lambda x: get_pred_and_cls(x, \"tool_use\", 0.5), axis=1)\n",
    "].name.values\n",
    "\n",
    "print(f\"BG model correct: {len(bg_correct)}\")\n",
    "print(f\"Baseline model correct: {len(bl_correct)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    train_df.utm.isin(bg_df[bg_df.name.isin(bg_correct)].utm.unique())\n",
    "].utm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    train_df.label.apply(lambda x: x[behaviours.index(\"tool_use\")] == 1)\n",
    "].utm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in behaviours:\n",
    "    utm_df = (\n",
    "        train_df[train_df.label.apply(lambda x: x[behaviours.index(b)] == 1)]\n",
    "        .utm.value_counts()\n",
    "        .reset_index()\n",
    "    )\n",
    "    print(b, utm_df.utm.nunique())\n",
    "    # print(b, calculate_imbalance_measures(utm_df)[\"scaled_pareto_ratio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the intersection of the two sets of videos\n",
    "intersection = set(bg_correct).intersection(set(bl_correct))\n",
    "print(f\"Intersection: {len(intersection)}\")\n",
    "\n",
    "# Find the difference between the two sets of videos\n",
    "diff = set(bg_correct).difference(set(bl_correct))\n",
    "print(f\"Difference: {len(diff)}\")\n",
    "\n",
    "# This show that the observed performance relates to the same set of videos\n",
    "# The 3 videos not predicted by the baseline model are from locations unobserved at training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_df[bg_df.name.isin(intersection)].utm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(train_df, behaviours, \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(\n",
    "    train_df[train_df.utm.isin(bg_df[bg_df.name.isin(bg_correct)].utm.unique())],\n",
    "    behavior_list=behaviours,\n",
    "    annot=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prevalence(df, cls):\n",
    "    # Iterate through rows and count the number of times cls is present\n",
    "    cls_count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"label\"][behaviours.index(cls)] == 1:\n",
    "            cls_count += 1\n",
    "    return cls_count / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prevalence(\n",
    "    train_df[train_df.utm.isin(bg_df[bg_df.name.isin(bg_correct)].utm.unique())],\n",
    "    \"tool_use\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
