{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    f1_score,\n",
    "    multilabel_precision,\n",
    "    multilabel_recall,\n",
    "    multilabel_average_precision,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load annotations and results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant paths\n",
    "train_results_file = (\n",
    "    \"../data/local_for_maksim/results/model=slow_r50-w-negatives_e=100_split=train.pkl\"\n",
    ")\n",
    "val_results_file = (\n",
    "    \"../data/local_for_maksim/results/model=slow_r50-w-negatives_e=100_split=val.pkl\"\n",
    ")\n",
    "metadata_file = \"../data/local_for_maksim/metadata/metadata.csv\"\n",
    "behavioural_labels_file = \"../data/behaviours.txt\"\n",
    "segements_file = \"../data/segements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    train_results_file,\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    train_data = pkl.load(f)\n",
    "\n",
    "with open(val_results_file, \"rb\") as f:\n",
    "    val_data = pkl.load(f)\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "with open(behavioural_labels_file, \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segements_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results2df(train_data, val_data, metadata_df):\n",
    "\n",
    "    # Process subclips\n",
    "    subclips = []\n",
    "    for i, split in enumerate([train_data, val_data]):\n",
    "        for name, pred, feat, label in zip(\n",
    "            split[\"names\"], split[\"preds\"], split[\"feats\"], split[\"labels\"]\n",
    "        ):\n",
    "            subclips.append(\n",
    "                {\n",
    "                    \"name\": name,\n",
    "                    \"split\": i,\n",
    "                    \"pred\": pred,\n",
    "                    \"feat\": feat,\n",
    "                    \"negative\": True if sum(label) == 0 else False,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(subclips, columns=[\"name\", \"split\", \"pred\", \"feat\", \"negative\"])\n",
    "\n",
    "    df[\"split\"] = df.split.map({0: \"train\", 1: \"val\"})\n",
    "    df = df.merge(metadata_df, how=\"left\", left_on=\"name\", right_on=\"subject_id\")\n",
    "\n",
    "    # Apply sigmoid to predictions\n",
    "    df[\"pred\"] = df.pred.apply(lambda x: torch.sigmoid(torch.tensor(x)))\n",
    "\n",
    "    # Convert label from str to int\n",
    "    df.label = df.label.apply(lambda x: np.array(ast.literal_eval(x)))\n",
    "\n",
    "    # Add negative\n",
    "    df[\"negative\"] = df.label.apply(lambda x: sum(x) == 0)\n",
    "\n",
    "    # Add global location count to dataframe\n",
    "    df[\"location_count\"] = df.utm.map(df.utm.value_counts())\n",
    "\n",
    "    # Return train and val dataframes\n",
    "    train_df = df[df.split == \"train\"]\n",
    "    val_df = df[df.split == \"val\"]\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def print_per_segement_performance(map, segment, show_per_class=False):\n",
    "    res = []\n",
    "    for i, (b, s) in enumerate(zip(map, segments)):\n",
    "        if s == segment:\n",
    "            res.append({behaviours[i]: b})\n",
    "    agg_values = []\n",
    "    for r in res:\n",
    "        for _, value in r.items():\n",
    "            agg_values.append(value)\n",
    "    if show_per_class:\n",
    "        print(f\"{segment}: {np.mean(agg_values):.2f} {res}\")\n",
    "    else:\n",
    "        print(f\"{segment}: {np.mean(agg_values):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return dfs with preds, feats, labels, and all metadata\n",
    "train_df, val_df = results2df(train_data, val_data, metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ct_location_segments(df, head=50, tail=10):\n",
    "    \"\"\"\n",
    "    Returns the location segments based on the given dataframe and thresholds.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input dataframe containing the location data.\n",
    "        head (int, optional): The threshold percentage for selecting locations that make up the top percentage of data. Defaults to 50.\n",
    "        tail (int, optional): The threshold count for selecting locations outside the top percentage with more than this count. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing three dataframes:\n",
    "            - head_locations: Dataframe containing the top locations and their video counts.\n",
    "            - tail_locations: Dataframe containing the locations outside the top percentage with more than the tail count.\n",
    "            - few_shot_locations: Dataframe containing the locations with fewer than the tail count.\n",
    "    \"\"\"\n",
    "    # Group by 'utm' and count the number of videos for each location\n",
    "    location_counts = train_df[\"utm\"].value_counts().reset_index()\n",
    "    location_counts.columns = [\"utm\", \"video_count\"]\n",
    "\n",
    "    # Calculate the total number of videos\n",
    "    total_videos = location_counts[\"video_count\"].sum()\n",
    "\n",
    "    # Sort locations by video count in descending order and calculate cumulative percentage\n",
    "    location_counts = location_counts.sort_values(\"video_count\", ascending=False)\n",
    "    location_counts[\"cumulative_count\"] = location_counts[\"video_count\"].cumsum()\n",
    "    location_counts[\"cumulative_percentage\"] = (\n",
    "        location_counts[\"cumulative_count\"] / total_videos * 100\n",
    "    )\n",
    "\n",
    "    # Select locations that make up 50% of the data\n",
    "    head_locations = location_counts[location_counts[\"cumulative_percentage\"] <= head]\n",
    "\n",
    "    # Calculate locations outside the top 50% with more than 10 samples\n",
    "    tail_locations = location_counts[location_counts[\"cumulative_percentage\"] > head]\n",
    "    tail_locations = tail_locations[tail_locations[\"video_count\"] > tail]\n",
    "\n",
    "    # Calculate locations with fewer than 10 samples\n",
    "    few_shot_locations = location_counts[location_counts[\"video_count\"] < tail]\n",
    "\n",
    "    return (\n",
    "        head_locations[[\"utm\", \"video_count\"]],\n",
    "        tail_locations[[\"utm\", \"video_count\"]],\n",
    "        few_shot_locations[[\"utm\", \"video_count\"]],\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_camera_locations_distribution(df, head=50, tail=10, use_proportion=False):\n",
    "    # Group by 'utm' and count the number of videos for each location\n",
    "    location_counts = df[\"utm\"].value_counts().reset_index()\n",
    "    location_counts.columns = [\"utm\", \"video_count\"]\n",
    "\n",
    "    # Calculate the total number of videos\n",
    "    total_videos = location_counts[\"video_count\"].sum()\n",
    "\n",
    "    # Sort locations by video count in descending order and calculate cumulative sum and percentage\n",
    "    location_counts = location_counts.sort_values(\"video_count\", ascending=False)\n",
    "    location_counts[\"cumulative_count\"] = location_counts[\"video_count\"].cumsum()\n",
    "    location_counts[\"cumulative_percentage\"] = (\n",
    "        location_counts[\"cumulative_count\"] / total_videos * 100\n",
    "    )\n",
    "\n",
    "    # Identify the indices for head (50%), tail (>10), and few-shot (<10) segments\n",
    "    head_index = location_counts[\n",
    "        location_counts[\"cumulative_percentage\"] <= head\n",
    "    ].index[-1]\n",
    "    tail_index = location_counts[location_counts[\"video_count\"] > tail].index[-1]\n",
    "\n",
    "    # Determine y-axis values based on use_proportion\n",
    "    y_values = (\n",
    "        location_counts[\"cumulative_percentage\"]\n",
    "        if use_proportion\n",
    "        else location_counts[\"cumulative_count\"]\n",
    "    )\n",
    "    y_label = (\n",
    "        \"Cumulative Proportion of Videos\"\n",
    "        if use_proportion\n",
    "        else \"Cumulative Number of Videos\"\n",
    "    )\n",
    "    y_max = 100 if use_proportion else total_videos\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(len(location_counts)), y_values, \"b-\")\n",
    "\n",
    "    # Add vertical lines and annotations for segments\n",
    "    plt.axvline(x=head_index, color=\"r\", linestyle=\"--\", label=\"Head (50%)\")\n",
    "    plt.axvline(x=tail_index, color=\"g\", linestyle=\"--\", label=\"Tail (>10 samples)\")\n",
    "\n",
    "    # Fill areas for each segment\n",
    "    plt.fill_between(\n",
    "        range(head_index + 1),\n",
    "        y_values[: head_index + 1],\n",
    "        alpha=0.3,\n",
    "        color=\"r\",\n",
    "        label=\"Head\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        range(head_index + 1, tail_index + 1),\n",
    "        y_values[head_index + 1 : tail_index + 1],\n",
    "        alpha=0.3,\n",
    "        color=\"g\",\n",
    "        label=\"Tail\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        range(tail_index + 1, len(location_counts)),\n",
    "        y_values[tail_index + 1 :],\n",
    "        alpha=0.3,\n",
    "        color=\"y\",\n",
    "        label=\"Few-shot\",\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Cumulative Distribution of Videos Across Camera Locations\")\n",
    "    plt.xlabel(\"Camera Locations (sorted by video count)\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "\n",
    "    # Add text annotations\n",
    "    plt.text(\n",
    "        head_index,\n",
    "        y_max / 2,\n",
    "        f\"Head: {head_index+1} locations\",\n",
    "        rotation=90,\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "    plt.text(\n",
    "        tail_index,\n",
    "        y_max / 2,\n",
    "        f\"Tail: {tail_index-head_index} locations\",\n",
    "        rotation=90,\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "    plt.text(\n",
    "        len(location_counts) - 1,\n",
    "        y_max / 2,\n",
    "        f\"Few-shot: {len(location_counts)-tail_index-1} locations\",\n",
    "        rotation=90,\n",
    "        verticalalignment=\"center\",\n",
    "    )\n",
    "\n",
    "    plt.ylim(0, y_max)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_df, t_df, f_df = return_ct_location_segments(train_df, head=50, tail=10)\n",
    "\n",
    "# Merge with original dataframe\n",
    "h_df = h_df.merge(train_df, on=\"utm\", how=\"left\")\n",
    "t_df = t_df.merge(train_df, on=\"utm\", how=\"left\")\n",
    "f_df = f_df.merge(train_df, on=\"utm\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "plot_camera_locations_distribution(train_df, head=50, tail=20, use_proportion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_behavior_distribution(df, behavior_list):\n",
    "    # Ensure the number of behaviors matches the length of multihot encodings\n",
    "    num_behaviors = len(df[\"label\"].iloc[0])\n",
    "    if len(behavior_list) != num_behaviors:\n",
    "        raise ValueError(\n",
    "            f\"The length of behavior_list ({len(behavior_list)}) does not match the number of behaviors in the data ({num_behaviors})\"\n",
    "        )\n",
    "\n",
    "    # Sum up the occurrences of each behavior\n",
    "    behavior_counts = np.sum(df[\"label\"].tolist(), axis=0)\n",
    "\n",
    "    # Calculate the percentage of videos featuring each behavior\n",
    "    behavior_percentages = (behavior_counts / len(df)) * 100\n",
    "\n",
    "    # Create a DataFrame for seaborn\n",
    "    plot_df = pd.DataFrame(\n",
    "        {\"Behavior\": behavior_list, \"Percentage\": behavior_percentages}\n",
    "    )\n",
    "\n",
    "    # Sort the DataFrame by percentage in descending order\n",
    "    plot_df = plot_df.sort_values(\"Percentage\", ascending=False)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create the bar plot\n",
    "    ax = sns.barplot(x=\"Behavior\", y=\"Percentage\", data=plot_df)\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(\"Distribution of Behaviors Across Videos\", fontsize=16)\n",
    "    plt.xlabel(\"Behaviors\", fontsize=12)\n",
    "    plt.ylabel(\"Percentage of Videos\", fontsize=12)\n",
    "    plt.ylim(0, max(plot_df[\"Percentage\"]) * 1.1)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # Add percentage labels on top of each bar\n",
    "    for i, v in enumerate(plot_df[\"Percentage\"]):\n",
    "        ax.text(i, v + 0.5, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Adjust layout to prevent cutting off labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_behavior_distribution(train_df, behaviours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregated_behavior_distribution(\n",
    "    df, behavior_list, segment_list, plot_type=\"bar\", segment=\"all\"\n",
    "):\n",
    "    # Ensure the lengths match\n",
    "    if len(behavior_list) != len(segment_list) or len(behavior_list) != len(\n",
    "        df[\"label\"].iloc[0]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Lengths of behavior_list, segment_list, and label encodings must match\"\n",
    "        )\n",
    "\n",
    "    if plot_type not in [\"bar\", \"pie\"]:\n",
    "        raise ValueError(\"plot_type must be either 'bar' or 'pie'\")\n",
    "\n",
    "    # Sum up the occurrences of each behavior\n",
    "    behavior_counts = np.sum(df[\"label\"].tolist(), axis=0)\n",
    "\n",
    "    # Calculate the percentage of videos featuring each behavior\n",
    "    behavior_percentages = (behavior_counts / len(df)) * 100\n",
    "\n",
    "    # Create a DataFrame for aggregation\n",
    "    plot_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Behavior\": behavior_list,\n",
    "            \"Percentage\": behavior_percentages,\n",
    "            \"Segment\": segment_list,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Aggregate percentages by segment\n",
    "    aggregated_df = plot_df.groupby(\"Segment\")[\"Percentage\"].sum().reset_index()\n",
    "\n",
    "    # Calculate average percentage per behavior in each segment\n",
    "    avg_df = (\n",
    "        plot_df.groupby(\"Segment\")\n",
    "        .agg(Avg_Percentage=(\"Percentage\", \"mean\"), Count=(\"Behavior\", \"count\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Merge aggregated_df with avg_df\n",
    "    merged_df = pd.merge(aggregated_df, avg_df, on=\"Segment\")\n",
    "\n",
    "    # Ensure all segments are present and in the correct order\n",
    "    all_segments = [\"head\", \"tail\", \"few_shot\"]\n",
    "    merged_df = merged_df.set_index(\"Segment\").reindex(all_segments).reset_index()\n",
    "    merged_df = merged_df.fillna(0)  # Fill NaN values with 0 for any missing segments\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    if plot_type == \"bar\":\n",
    "        # Create the bar plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.barplot(\n",
    "            x=\"Segment\",\n",
    "            y=\"Percentage\",\n",
    "            data=merged_df,\n",
    "            palette=\"viridis\",\n",
    "            order=all_segments,\n",
    "        )\n",
    "\n",
    "        plt.title(\"Aggregated Distribution of Behaviors by Segment\", fontsize=16)\n",
    "        plt.xlabel(\"Segment\", fontsize=12)\n",
    "        plt.ylabel(\"Total Percentage of Videos\", fontsize=12)\n",
    "        plt.ylim(0, min(100, merged_df[\"Percentage\"].max() * 1.1))\n",
    "\n",
    "        # Add percentage labels on top of each bar\n",
    "        for i, row in merged_df.iterrows():\n",
    "            ax.text(\n",
    "                i,\n",
    "                row[\"Percentage\"] + 0.5,\n",
    "                f'{row[\"Percentage\"]:.1f}%',\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "\n",
    "            # Add average percentage and count as text\n",
    "            ax.text(\n",
    "                i,\n",
    "                row[\"Percentage\"] / 2,\n",
    "                f\"Avg: {row['Avg_Percentage']:.1f}%\\nCount: {row['Count']}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontweight=\"bold\",\n",
    "            )\n",
    "\n",
    "    elif plot_type == \"pie\":\n",
    "        # Create the pie chart\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        colors = sns.color_palette(\"viridis\", n_colors=len(all_segments))\n",
    "        plt.pie(\n",
    "            merged_df[\"Percentage\"],\n",
    "            labels=merged_df[\"Segment\"],\n",
    "            autopct=\"%1.1f%%\",\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "        )\n",
    "        plt.title(\n",
    "            f\"Proportion of Behaviors in {segment.capitalize()} Segment Camera Locations\",\n",
    "            fontsize=16,\n",
    "        )\n",
    "\n",
    "        legend_labels = [\n",
    "            f\"{segment} (Avg: {row['Avg_Percentage']:.1f}%, Count: {row['Count']})\"\n",
    "            for segment, row in merged_df.iterrows()\n",
    "        ]\n",
    "        plt.legend(\n",
    "            legend_labels,\n",
    "            title=\"Segment Details\",\n",
    "            loc=\"center left\",\n",
    "            bbox_to_anchor=(1, 0, 0.5, 1),\n",
    "        )\n",
    "\n",
    "        plt.axis(\"equal\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = plot_aggregated_behavior_distribution(\n",
    "    train_df, behaviours, segments, plot_type=\"pie\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregated_behavior_distribution(\n",
    "    h_df, behaviours, segments, plot_type=\"pie\", segment=\"head\"\n",
    ")\n",
    "plot_aggregated_behavior_distribution(\n",
    "    t_df, behaviours, segments, plot_type=\"pie\", segment=\"tail\"\n",
    ")\n",
    "plot_aggregated_behavior_distribution(\n",
    "    f_df, behaviours, segments, plot_type=\"pie\", segment=\"few_shot\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
