{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_f1_score,\n",
    "    multilabel_precision,\n",
    "    multilabel_recall,\n",
    ")\n",
    "\n",
    "from data_utils import results2df\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Slowfast imports\n",
    "from slowfast.models import build_model\n",
    "from slowfast.utils.parser import load_config, alt_parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/model=slow_r50_ds=panaf_seq_fd_only_feats=train_feats.pkl\"\n",
    "orig_val_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/model=slow_r50_ds=panaf_seq_fd_only_e=200_feats=val_feats.pkl\"\n",
    "val_sub_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/model=slow_r50_ds=panaf_seq_fg_minus_bg_lambda_e=200_split=val_feats.pkl\"\n",
    "metadata_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/with_negative_pairing/new_metadata.csv\"\n",
    "segments_file = \"../dataset/metadata/segments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = pkl.load(f)\n",
    "\n",
    "with open(orig_val_path, \"rb\") as f:\n",
    "    orig_val_data = pkl.load(f)\n",
    "\n",
    "with open(val_sub_path, \"rb\") as f:\n",
    "    sub_val_data = pkl.load(f)\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "with open(\"../dataset/metadata/behaviours.txt\", \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segments_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, labels):\n",
    "    # Convert preds and labels to tensors\n",
    "    preds, labels = np.stack(preds), np.stack(labels)\n",
    "    preds, labels = torch.tensor(preds, dtype=torch.float32), torch.tensor(labels)\n",
    "    # Calculate metrics\n",
    "    f1 = multilabel_f1_score(preds, labels, num_labels=14, average=\"none\")\n",
    "    precision = multilabel_precision(preds, labels, num_labels=14, average=\"none\")\n",
    "    recall = multilabel_recall(preds, labels, num_labels=14, average=\"none\")\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_domain_shift(train_df, val_df, pred_column, behaviours):\n",
    "\n",
    "    store = []\n",
    "\n",
    "    for idx in range(len(behaviours)):\n",
    "        val_agg_df = val_df[val_df.label.apply(lambda x: x[idx] == 1)]\n",
    "        train_agg_df = train_df[train_df.label.apply(lambda x: x[idx] == 1)]\n",
    "\n",
    "        overall_f1, overall_precision, overall_recall = calculate_metrics(\n",
    "            val_agg_df[pred_column].values, val_agg_df[\"label\"].values\n",
    "        )\n",
    "\n",
    "        mutual_df = val_agg_df[val_agg_df[\"utm\"].isin(train_agg_df[\"utm\"])]\n",
    "        mutual_videos = len(mutual_df[\"utm\"].unique())\n",
    "\n",
    "        mutual_f1, mutual_precision, mutual_recall = calculate_metrics(\n",
    "            mutual_df[pred_column].values, mutual_df[\"label\"].values\n",
    "        )\n",
    "\n",
    "        exclusive_df = val_agg_df[~val_agg_df[\"utm\"].isin(train_agg_df[\"utm\"])]\n",
    "        exclusive_videos = len(exclusive_df[\"utm\"].unique())\n",
    "\n",
    "        exclusive_f1, exclusive_precision, exclusive_recall = calculate_metrics(\n",
    "            exclusive_df[pred_column].values, exclusive_df[\"label\"].values\n",
    "        )\n",
    "\n",
    "        store.append(\n",
    "            {\n",
    "                \"behaviour\": behaviours[idx],\n",
    "                \"mutual_ct_loc\": mutual_videos,\n",
    "                \"exclusive_ct_loc\": exclusive_videos,\n",
    "                \"mutual_loc_prop\": round(\n",
    "                    mutual_videos / (exclusive_videos + mutual_videos), 2\n",
    "                ),\n",
    "                \"overall_recall\": overall_recall[idx].item(),\n",
    "                \"overall_precision\": overall_precision[idx].item(),\n",
    "                \"overall_f1\": overall_f1[idx].item(),\n",
    "                \"mutual_recall\": mutual_recall[idx].item(),\n",
    "                \"mutual_precision\": mutual_precision[idx].item(),\n",
    "                \"mutual_f1\": mutual_f1[idx].item(),\n",
    "                \"exclusive_recall\": exclusive_recall[idx].item(),\n",
    "                \"exclusive_precision\": exclusive_precision[idx].item(),\n",
    "                \"exclusive_f1\": exclusive_f1[idx].item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(store)\n",
    "\n",
    "        # Round all numerical columns to 2 decimal places\n",
    "        df = df.round(4)\n",
    "\n",
    "    return mutual_df, exclusive_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results2df(df, split):\n",
    "    # Process subclips\n",
    "    subclips = []\n",
    "    if split == \"train\":\n",
    "        for name, pred, feat, label in zip(\n",
    "            df[\"names\"], df[\"preds\"], df[\"feats\"], df[\"labels\"]\n",
    "        ):\n",
    "            subclips.append(\n",
    "                {\n",
    "                    \"name\": name,\n",
    "                    \"split\": split,\n",
    "                    \"pred\": pred,\n",
    "                    \"feat\": feat,\n",
    "                    \"negative\": True if sum(label) == 0 else False,\n",
    "                    \"label\": label,\n",
    "                }\n",
    "            )\n",
    "        df = pd.DataFrame(\n",
    "            subclips, columns=[\"name\", \"split\", \"pred\", \"feat\", \"negative\", \"label\"]\n",
    "        )\n",
    "    else:\n",
    "        for name, pred, label in zip(df[\"names\"], df[\"preds\"], df[\"labels\"]):\n",
    "            subclips.append(\n",
    "                {\n",
    "                    \"name\": name,\n",
    "                    \"split\": split,\n",
    "                    \"pred\": pred,\n",
    "                    \"negative\": True if sum(label) == 0 else False,\n",
    "                    \"label\": label,\n",
    "                }\n",
    "            )\n",
    "        df = pd.DataFrame(\n",
    "            subclips, columns=[\"name\", \"split\", \"pred\", \"negative\", \"label\"]\n",
    "        )\n",
    "    # Move all preds and labels to the cpu\n",
    "    df[\"pred\"] = df.pred.apply(lambda x: x.detach().cpu().numpy())\n",
    "    df[\"label\"] = df.label.apply(lambda x: x.detach().cpu().numpy())\n",
    "\n",
    "    df[\"pred\"] = df.pred.apply(lambda x: torch.sigmoid(torch.tensor(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = results2df(train_data, \"train\")\n",
    "val_df = results2df(orig_val_data, \"val\")\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"utm\", \"value\"]],\n",
    "    left_on=\"name\",\n",
    "    right_on=\"subject_id_fg\",\n",
    ")\n",
    "val_df = val_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"utm\", \"value\"]],\n",
    "    left_on=\"name\",\n",
    "    right_on=\"subject_id_fg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_df, exclusive_df, original_df = measure_domain_shift(\n",
    "    train_df, val_df, pred_column=\"pred\", behaviours=behaviours\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df[\n",
    "    [\"behaviour\", \"mutual_loc_prop\", \"overall_f1\", \"mutual_f1\", \"exclusive_f1\"]\n",
    "].sort_values(by=\"mutual_loc_prop\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df.overall_f1.mean())\n",
    "print(original_df.mutual_f1.mean())\n",
    "print(original_df.exclusive_f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_val_df = results2df(sub_val_data, \"val\")\n",
    "sub_val_df = sub_val_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"utm\"]], left_on=\"name\", right_on=\"subject_id_fg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_df, exclusive_df, sub_df = measure_domain_shift(\n",
    "    train_df, sub_val_df, pred_column=\"pred\", behaviours=behaviours\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\n",
    "    [\"behaviour\", \"mutual_loc_prop\", \"overall_f1\", \"mutual_f1\", \"exclusive_f1\"]\n",
    "].sort_values(by=\"mutual_loc_prop\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Overall F1: {sub_df.overall_f1.mean()}\")\n",
    "print(f\"Mutual F1: {sub_df.mutual_f1.mean()}\")\n",
    "print(f\"Exclusive F1: {sub_df.exclusive_f1.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(\n",
    "    {\n",
    "        \"behaviours\": behaviours,\n",
    "        \"segments\": segments,\n",
    "        \"overall_f1\": original_df.overall_f1,\n",
    "        \"mutual_f1\": original_df.mutual_f1,\n",
    "        \"exclusive_f1\": original_df.exclusive_f1,\n",
    "        \"sub_overall_f1\": sub_df.overall_f1,\n",
    "        \"sub_mutual_f1\": sub_df.mutual_f1,\n",
    "        \"sub_exclusive_f1\": sub_df.exclusive_f1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[\n",
    "    [\n",
    "        \"behaviours\",\n",
    "        \"segments\",\n",
    "        \"overall_f1\",\n",
    "        \"sub_overall_f1\",\n",
    "        \"mutual_f1\",\n",
    "        \"sub_mutual_f1\",\n",
    "        \"exclusive_f1\",\n",
    "        \"sub_exclusive_f1\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for overall_f1 and sub_overall_f1 print per segment results\n",
    "for s in res_df.segments.unique():\n",
    "    print(\n",
    "        f\"{s}\\n\", res_df[res_df.segments == s][[\"overall_f1\", \"sub_overall_f1\"]].mean()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for overall_f1 and sub_overall_f1 print per segment results\n",
    "for s in res_df.segments.unique():\n",
    "    print(f\"{s}\\n\", res_df[res_df.segments == s][[\"mutual_f1\", \"sub_mutual_f1\"]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for overall_f1 and sub_overall_f1 print per segment results\n",
    "for s in res_df.segments.unique():\n",
    "    print(\n",
    "        f\"{s}\\n\",\n",
    "        res_df[res_df.segments == s][[\"exclusive_f1\", \"sub_exclusive_f1\"]].mean(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between mutual_loc_prop and overall_f1\n",
    "overall_corr = original_df[[\"mutual_loc_prop\", \"overall_f1\"]].corr().iloc[0, 1]\n",
    "mutual_corr = original_df[[\"mutual_loc_prop\", \"mutual_f1\"]].corr().iloc[0, 1]\n",
    "exclusive_corr = original_df[[\"mutual_loc_prop\", \"exclusive_f1\"]].corr().iloc[0, 1]\n",
    "\n",
    "print(f\"Overall correlation: {overall_corr}\")\n",
    "print(f\"Mutual correlation: {mutual_corr}\")\n",
    "print(f\"Exclusive correlation: {exclusive_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"feat\"] = train_df.feat.apply(lambda x: x.detach().cpu())\n",
    "val_df[\"feat\"] = val_df.feat.apply(lambda x: x.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pairwise cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    train_df.groupby(\"value\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix, index=grouped_df[\"value\"], columns=grouped_df[\"value\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8), dpi=300)\n",
    "sns.heatmap(similarity_df, annot=False, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values and index from the similarity dataframe\n",
    "values = similarity_df.values\n",
    "index = similarity_df.index.tolist()\n",
    "\n",
    "# Create a mask to exclude the diagonal\n",
    "mask = np.triu(np.ones_like(values, dtype=bool), k=1)\n",
    "\n",
    "# Create a list to store similarity pairs\n",
    "similarity_pairs = []\n",
    "\n",
    "# Iterate through the upper triangle of the matrix\n",
    "for i in range(len(index)):\n",
    "    for j in range(i + 1, len(index)):\n",
    "        if mask[i, j]:\n",
    "            similarity_pairs.append(\n",
    "                {\"value1\": index[i], \"value2\": index[j], \"similarity\": values[i, j]}\n",
    "            )\n",
    "\n",
    "# Convert to dataframe and sort by similarity\n",
    "similarity_df = pd.DataFrame(similarity_pairs)\n",
    "similarity_df = similarity_df.sort_values(\"similarity\", ascending=False)\n",
    "\n",
    "# Take top N pairs (e.g., top 20)\n",
    "top_n = 20\n",
    "top_pairs = similarity_df.head(top_n)\n",
    "\n",
    "# Create pair labels\n",
    "top_pairs[\"pair\"] = top_pairs[\"value1\"] + \" - \" + top_pairs[\"value2\"]\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the Seaborn bar plot\n",
    "sns.barplot(x=\"similarity\", y=\"pair\", data=top_pairs, orient=\"h\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(\n",
    "    \"Top 20 Value Pairs by Cosine Similarity (Excluding Self-Similarity)\", fontsize=16\n",
    ")\n",
    "plt.xlabel(\"Cosine Similarity\", fontsize=12)\n",
    "plt.ylabel(\"Value Pairs\", fontsize=12)\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(x, behaviours, segments):\n",
    "    segment_code = []\n",
    "    split_x = x.split(\",\")\n",
    "    for i, seg in enumerate(segments):\n",
    "        if behaviours[i] in split_x:\n",
    "            segment_code.append(seg)\n",
    "    # segment_code = list(set(segment_code))\n",
    "    return \",\".join(sorted(segment_code))\n",
    "\n",
    "\n",
    "def get_seg_code(x, unique=True):\n",
    "    seg_code = []\n",
    "    try:\n",
    "        split_x = x.split(\",\")\n",
    "        for seg in split_x:\n",
    "            seg_code.append(seg[0].capitalize())\n",
    "        if unique:\n",
    "            seg_code = list(set(seg_code))\n",
    "        seg_code = \"\".join(sorted(seg_code))\n",
    "    except:\n",
    "        seg_code = \"N\"\n",
    "    return seg_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label_combination\"] = train_df.value.apply(\n",
    "    lambda x: get_segment(x, behaviours, segments)\n",
    ")\n",
    "train_df[\"full_code\"] = train_df[\"label_combination\"].apply(\n",
    "    lambda x: get_seg_code(x, unique=False)\n",
    ")\n",
    "train_df[\"unique_code\"] = train_df[\"label_combination\"].apply(\n",
    "    lambda x: get_seg_code(x, unique=True)\n",
    ")\n",
    "\n",
    "val_df[\"label_combination\"] = val_df.value.apply(\n",
    "    lambda x: get_segment(x, behaviours, segments)\n",
    ")\n",
    "val_df[\"full_code\"] = val_df[\"label_combination\"].apply(\n",
    "    lambda x: get_seg_code(x, unique=False)\n",
    ")\n",
    "val_df[\"unique_code\"] = val_df[\"label_combination\"].apply(\n",
    "    lambda x: get_seg_code(x, unique=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    train_df.groupby(\"unique_code\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=grouped_df[\"unique_code\"],\n",
    "    columns=grouped_df[\"unique_code\"],\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "sns.heatmap(similarity_df, annot=True, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    train_df.groupby(\"full_code\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix, index=grouped_df[\"full_code\"], columns=grouped_df[\"full_code\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "sns.heatmap(similarity_df, annot=False, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    val_df.groupby(\"unique_code\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=grouped_df[\"unique_code\"],\n",
    "    columns=grouped_df[\"unique_code\"],\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "sns.heatmap(similarity_df, annot=True, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    val_df.groupby(\"full_code\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix, index=grouped_df[\"full_code\"], columns=grouped_df[\"full_code\"]\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "sns.heatmap(similarity_df, annot=False, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifying segment averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/configs/SLOW_8x8_R50_TEST.yaml\"\n",
    "path_to_ckpt = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/checkpoint_epoch_00200.pyth\"\n",
    "\n",
    "args = alt_parse_args()[:-1]\n",
    "cfg = load_config(\n",
    "    args[0],\n",
    "    path_to_config=path_to_config,\n",
    ")\n",
    "checkpoint = torch.load(path_to_ckpt)\n",
    "\n",
    "model = build_model(cfg)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "projection = model.head.projection\n",
    "projection.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = (\n",
    "    val_df.groupby(\"unique_code\")[\"feat\"]\n",
    "    .apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
    "    .reset_index()\n",
    ")\n",
    "grouped_df[\"preds\"] = grouped_df.feat.apply(\n",
    "    lambda x: torch.sigmoid(projection(torch.tensor(x)).detach().cpu())\n",
    ")\n",
    "\n",
    "grouped_df[\"preds\"] = grouped_df[\"preds\"].apply(lambda x: x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column of lists into multiple columns\n",
    "grouped_df = pd.concat(\n",
    "    [grouped_df.drop([\"preds\"], axis=1), grouped_df[\"preds\"].apply(pd.Series)],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Add behaviour names to the columns\n",
    "grouped_df.columns = [\"unique_code\", \"pred\"] + behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour_map = plt.cm.get_cmap(\"tab20\", 14)\n",
    "grouped_df[behaviours].plot(kind=\"bar\", figsize=(12, 8), colormap=colour_map)\n",
    "\n",
    "# Plot uniqe_code on x-axis\n",
    "plt.xticks(range(len(grouped_df)), grouped_df[\"unique_code\"], rotation=45)\n",
    "\n",
    "# Move legend outside of plot\n",
    "plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot preds\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(grouped_df.preds.apply(lambda x: x.numpy()), bins=50)\n",
    "plt.title(\"Predictions Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'feat' column to a list of numpy arrays\n",
    "embeddings = np.stack(grouped_df[\"feat\"].values)\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Create a dataframe with the similarity matrix\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=grouped_df[\"unique_code\"],\n",
    "    columns=grouped_df[\"unique_code\"],\n",
    ")\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 12), dpi=100)\n",
    "sns.heatmap(similarity_df, annot=True, cmap=\"viridis\", cbar=True)\n",
    "plt.title(\"Pairwise Cosine Similarity Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
