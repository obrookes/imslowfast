{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer-based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "d_model = 256\n",
    "bs = 8\n",
    "sos_idx = 1\n",
    "vocab_size = 15  # num of classes inc. SOS\n",
    "input_len = 4  # num of clips\n",
    "output_len = 25  # max seq len\n",
    "\n",
    "# Define the model\n",
    "encoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=d_model, nhead=4, batch_first=True\n",
    ").to(device)\n",
    "encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=6).to(device)\n",
    "\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    d_model=d_model, nhead=4, batch_first=True\n",
    ").to(device)\n",
    "decoder = nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=6).to(device)\n",
    "\n",
    "decoder_emb = nn.Embedding(vocab_size, d_model)\n",
    "predictor = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "# for a single batch x\n",
    "x = torch.randn(bs, input_len, d_model).to(device)\n",
    "y = torch.randint(0, vocab_size, (bs, output_len)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl18206/anaconda3/envs/dataset-upgrade/lib/python3.8/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([8, 4, 256])\n",
      "Decoder output shape: torch.Size([8, 25, 256])\n",
      "Final output shape: torch.Size([8, 25, 15])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass of the model\n",
    "encoder_output = encoder(x)\n",
    "\n",
    "tgt_emb = decoder_emb(y)\n",
    "tgt_mask = torch.nn.Transformer().generate_square_subsequent_mask(output_len).to(device)\n",
    "decoder_output = decoder(tgt=tgt_emb, tgt_mask=tgt_mask, memory=encoder_output)\n",
    "output = predictor(decoder_output)\n",
    "\n",
    "print(\"Encoder output shape:\", encoder_output.shape)\n",
    "print(\"Decoder output shape:\", decoder_output.shape)\n",
    "print(\"Final output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "encoder_output = encoder(x)  # (bs, input_len, d_model)\n",
    "\n",
    "# initialized the input of the decoder with sos_idx (start of sentence token idx)\n",
    "output = torch.ones(bs, output_len).long().to(device) * sos_idx\n",
    "\n",
    "for t in range(1, output_len):\n",
    "    tgt_emb = decoder_emb(output[:, :t])\n",
    "    tgt_mask = torch.nn.Transformer().generate_square_subsequent_mask(t).to(device)\n",
    "\n",
    "    decoder_output = decoder(tgt=tgt_emb, memory=encoder_output, tgt_mask=tgt_mask)\n",
    "\n",
    "    pred_proba_t = predictor(decoder_output[:, -1, :])\n",
    "    output_t = pred_proba_t.data.topk(1)[1].squeeze()\n",
    "    output[:, t] = output_t\n",
    "\n",
    "print(\"Output shape:\", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset-upgrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
