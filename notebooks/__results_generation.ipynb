{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_utils import (\n",
    "    results2df,\n",
    ")\n",
    "from plot_utils import plot_behavior_distribution\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_average_precision,\n",
    "    multilabel_f1_score,\n",
    ")\n",
    "from matplotlib.colors import rgb2hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_file = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/with_negative_pairing/new_metadata.csv\"\n",
    "behaviours_file = \"../dataset/metadata/behaviours.txt\"\n",
    "segments_file = \"../dataset/metadata/segments.txt\"\n",
    "\n",
    "\n",
    "metadata_df = pd.read_csv(metadata_file)\n",
    "\n",
    "with open(behaviours_file, \"rb\") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(segments_file, \"rb\") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]\n",
    "\n",
    "dumy_aps = [\n",
    "    0.0235,\n",
    "    0.0531,\n",
    "    0.1467,\n",
    "    0.1292,\n",
    "    0.0346,\n",
    "    0.2582,\n",
    "    0.0776,\n",
    "    0.1038,\n",
    "    0.0155,\n",
    "    0.0115,\n",
    "    0.4553,\n",
    "    0.1002,\n",
    "    0.5724,\n",
    "    0.0563,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, round_to=3, show_per_class=True):\n",
    "    map_values = multilabel_average_precision(\n",
    "        torch.tensor(np.stack(df[\"pred\"])),\n",
    "        torch.tensor(np.stack(df[\"label\"])),\n",
    "        num_labels=14,\n",
    "        average=\"none\",\n",
    "        # thresholds=200,\n",
    "    )\n",
    "    avg_map = round(map_values.mean().item(), round_to)\n",
    "    if show_per_class:\n",
    "        map_values_list = []\n",
    "        for v in map_values:\n",
    "            map_v = round(v.item(), round_to)\n",
    "            map_values_list.append(map_v)\n",
    "\n",
    "        return map_values_list\n",
    "    return avg_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/paper_results\"\n",
    "\n",
    "results_df = None\n",
    "\n",
    "# Get paths to all pickle files\n",
    "val_paths = []\n",
    "for root, dirs, files in os.walk(val_results):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pkl\"):\n",
    "            val_paths.append(os.path.join(root, file))\n",
    "\n",
    "for val_path in val_paths:\n",
    "\n",
    "    col_name = val_path.split(\"/\")[-2]\n",
    "\n",
    "    with open(\n",
    "        val_path,\n",
    "        \"rb\",\n",
    "    ) as f:\n",
    "        val_data = pkl.load(f)\n",
    "\n",
    "    train_df, val_df = results2df(\n",
    "        val_data, val_data, metadata_df, right_on=\"subject_id_fg\"\n",
    "    )\n",
    "\n",
    "    if results_df is None:\n",
    "        results_df = pd.DataFrame(\n",
    "            {\n",
    "                \"behaviour\": behaviours,\n",
    "                \"segment\": segments,\n",
    "                f\"{col_name}\": calculate_metrics(val_df),\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        results_df[col_name] = calculate_metrics(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"segment_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    [\n",
    "        \"behaviour\",\n",
    "        \"model=slow_r50_e300_bg-only\",\n",
    "        \"model=slow_r50_e200_baseline_results\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(\"segment\")[results_df.columns[2:]].mean().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
