{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl18206/anaconda3/envs/slowfast/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/dl18206/anaconda3/envs/slowfast/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import ast\n",
    "import mmcv\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torchmetrics.functional.classification import (\n",
    "    multilabel_f1_score,\n",
    "    multilabel_precision,\n",
    "    multilabel_recall,\n",
    ")\n",
    "\n",
    "from data_utils import results2df\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Slowfast imports\n",
    "from slowfast.models import build_model\n",
    "from slowfast.utils.parser import load_config, alt_parse_args\n",
    "from slowfast.datasets.loader import construct_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59e843cd90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating few-shot annotation file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60910995.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "      <td>display,aggression,piloerection,climbing,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36070556.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>aggression,display,vocalisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36070537.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]</td>\n",
       "      <td>resting,travel,vocalisation,display,aggression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36070523.mp4</td>\n",
       "      <td>[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>display,aggression,object_carrying,bipedal,cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>59759678.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>climbing,aggression,display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>36072978.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>aggression,object_carrying,display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>36072994.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>display,vocalisation,aggression,climbing,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>36072986.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>aggression,vocalisation,display,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>36072949.mp4</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>display,bipedal,object_carrying,aggression,voc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>32836460.mp4</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]</td>\n",
       "      <td>camera_reaction,aggression,piloerection,vocali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>36070430.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>aggression,display,vocalisation,object_carrying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>acp000auq2.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>vocalisation,aggression,display,climbing,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>36072997.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>display,vocalisation,climbing,aggression,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>36073384.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]</td>\n",
       "      <td>display,resting,travel,display,aggression,voca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>acp000c7n9.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>display,aggression,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>36070561.mp4</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>camera_reaction,vocalisation,object_carrying,d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>36067981.mp4</td>\n",
       "      <td>[1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>display,aggression,vocalisation,object_carryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>acp0005a9y.mp4</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]</td>\n",
       "      <td>aggression,camera_reaction,object_carrying,dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>acp0005652.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]</td>\n",
       "      <td>aggression,piloerection,vocalisation,object_ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>acp00053b2.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]</td>\n",
       "      <td>aggression,display,travel,vocalisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>acp000dkt6.mp4</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
       "      <td>camera_reaction,aggression,resting,travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>36144032.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "      <td>aggression,display,vocalisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>36074337.mp4</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]</td>\n",
       "      <td>aggression,climbing,display,resting,vocalisati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>34019603.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]</td>\n",
       "      <td>aggression,feeding,resting,tool_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>36070149.mp4</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>display,aggression,travel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id                                       label  \\\n",
       "8      60910995.mp4  [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0]   \n",
       "15     36070556.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "20     36070537.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]   \n",
       "24     36070523.mp4  [1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]   \n",
       "37     59759678.mp4  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "54     36072978.mp4  [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "59     36072994.mp4  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "62     36072986.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "68     36072949.mp4  [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]   \n",
       "78     32836460.mp4  [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]   \n",
       "97     36070430.mp4  [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]   \n",
       "103  acp000auq2.mp4  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "108    36072997.mp4  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "141    36073384.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1]   \n",
       "175  acp000c7n9.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "231    36070561.mp4  [1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]   \n",
       "267    36067981.mp4  [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]   \n",
       "340  acp0005a9y.mp4  [1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1]   \n",
       "403  acp0005652.mp4  [1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]   \n",
       "456  acp00053b2.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]   \n",
       "466  acp000dkt6.mp4  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]   \n",
       "475    36144032.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]   \n",
       "553    36074337.mp4  [1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]   \n",
       "641    34019603.mp4  [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]   \n",
       "699    36070149.mp4  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "\n",
       "                                                 value  \n",
       "8      display,aggression,piloerection,climbing,travel  \n",
       "15                     aggression,display,vocalisation  \n",
       "20      resting,travel,vocalisation,display,aggression  \n",
       "24   display,aggression,object_carrying,bipedal,cli...  \n",
       "37                         climbing,aggression,display  \n",
       "54                  aggression,object_carrying,display  \n",
       "59     display,vocalisation,aggression,climbing,travel  \n",
       "62              aggression,vocalisation,display,travel  \n",
       "68   display,bipedal,object_carrying,aggression,voc...  \n",
       "78   camera_reaction,aggression,piloerection,vocali...  \n",
       "97     aggression,display,vocalisation,object_carrying  \n",
       "103    vocalisation,aggression,display,climbing,travel  \n",
       "108    display,vocalisation,climbing,aggression,travel  \n",
       "141  display,resting,travel,display,aggression,voca...  \n",
       "175                          display,aggression,travel  \n",
       "231  camera_reaction,vocalisation,object_carrying,d...  \n",
       "267  display,aggression,vocalisation,object_carryin...  \n",
       "340  aggression,camera_reaction,object_carrying,dis...  \n",
       "403  aggression,piloerection,vocalisation,object_ca...  \n",
       "456             aggression,display,travel,vocalisation  \n",
       "466          camera_reaction,aggression,resting,travel  \n",
       "475                    aggression,display,vocalisation  \n",
       "553  aggression,climbing,display,resting,vocalisati...  \n",
       "641                aggression,feeding,resting,tool_use  \n",
       "699                          display,aggression,travel  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/train.csv\"\n",
    "val_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/val.csv\"\n",
    "metadata_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/with_negative_pairing/new_metadata.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "train_df.columns = [\"subject_id\", \"label\"]\n",
    "val_df.columns = [\"subject_id\", \"label\"]\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "with open(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/behaviours.txt\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"value\"]], right_on=\"subject_id_fg\", left_on=\"subject_id\"\n",
    ")\n",
    "\n",
    "val_df = val_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"value\"]], right_on=\"subject_id_fg\", left_on=\"subject_id\"\n",
    ")\n",
    "\n",
    "\n",
    "def is_fs(x):\n",
    "    fs_behaviours = [\"aggression\"]\n",
    "    for b in fs_behaviours:\n",
    "        if b == x:\n",
    "            return True\n",
    "    for b in fs_behaviours:\n",
    "        if b in x.split(\",\"):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "train_df[\n",
    "    (train_df[\"value\"].apply(is_fs)) & (train_df.subject_id.str.startswith(\"acp\"))\n",
    "][[\"subject_id\", \"label\", \"value\"]]\n",
    "\n",
    "val_df[(val_df[\"value\"].apply(is_fs))][[\"subject_id\", \"label\", \"value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_neg = pd.read_csv(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/with_negative_pairing/standard/val.csv\"\n",
    ")\n",
    "val_df_neg.columns = [\"fg\", \"bg\", \"label\", \"negative\", \"utm_code\"]\n",
    "val_df_neg = val_df_neg.merge(\n",
    "    metadata[[\"subject_id_fg\", \"value\"]], right_on=\"subject_id_fg\", left_on=\"fg\"\n",
    ")[[\"fg\", \"bg\", \"label\", \"value\"]]\n",
    "\n",
    "fs_val_df_neg = val_df_neg[val_df_neg[\"value\"].apply(is_fs)]\n",
    "fs_labels = fs_val_df_neg.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temporal activation maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLING.BALANCED: False; BALANCE_TYPE: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n",
      "/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/slowfast/datasets/decoder.py:335: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  video_tensor = torch.from_numpy(np.frombuffer(video_handle, dtype=np.uint8))\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "path_to_config = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/configs/SLOW_8x8_R50_Local.yaml\"\n",
    "path_to_ckpt = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/checkpoint_epoch_00100.pyth\"\n",
    "\n",
    "args = alt_parse_args()[:-1]\n",
    "cfg = load_config(\n",
    "    args[0],\n",
    "    path_to_config=path_to_config,\n",
    ")\n",
    "checkpoint = torch.load(path_to_ckpt, map_location=\"cpu\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "classifier = model.head.projection\n",
    "\n",
    "# Load the data\n",
    "loader = construct_loader(cfg, \"test\")  # dataset = build_dataset(\"tap\", cfg, \"train\")\n",
    "inputs, labels, index, time, meta = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funcs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_map(model, sample):\n",
    "    with torch.no_grad():\n",
    "        feature_map = model.s5(\n",
    "            model.s4(model.s3(model.s2(model.s1([sample.unsqueeze(0)]))))\n",
    "        )[\n",
    "            0\n",
    "        ]  # TODO: Investigate features at earlier layers\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "def extract_frame_wise_features(feature_map, t):\n",
    "    spatially_pooled = F.adaptive_avg_pool3d(feature_map, (t, 1, 1))\n",
    "    frame_wise_features = torch.flatten(spatially_pooled, start_dim=2)\n",
    "    return frame_wise_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample\n",
    "sample_index = 0\n",
    "label = labels[sample_index]\n",
    "sample = inputs[0][sample_index]\n",
    "negative_sample = inputs[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature maps for fg and bg\n",
    "feature_map = get_feature_map(model, sample)\n",
    "negative_feature_map = get_feature_map(model, negative_sample)\n",
    "framewise_features = extract_frame_wise_features(feature_map, t=16)\n",
    "negative_framewise_features = extract_frame_wise_features(negative_feature_map, t=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute frame-wise cosine similarity for\n",
    "normalise = False\n",
    "framewise_features = framewise_features.squeeze(0)\n",
    "framewise_features = framewise_features.T\n",
    "if normalise:\n",
    "    framewise_features = F.normalize(framewise_features, p=2, dim=1)\n",
    "framewise_cosine_similarity = torch.mm(framewise_features, framewise_features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_wise_logits = []\n",
    "for feat in framewise_features:\n",
    "    frame_wise_logits.append(torch.sigmoid(classifier(feat).detach()).numpy())\n",
    "frame_wise_logits = np.array(frame_wise_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video feats and logits\n",
    "video_level_features = F.adaptive_avg_pool3d(feature_map, (1, 1, 1))\n",
    "video_level_features = torch.flatten(video_level_features, start_dim=1)\n",
    "video_level_logits = torch.sigmoid(classifier(video_level_features)).detach().numpy()\n",
    "video_level_logits = np.array(video_level_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cosine similarity matrix\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(framewise_cosine_similarity.detach().numpy(), cmap=\"viridis\", annot=True)\n",
    "plt.title(\"Frame-wise cosine similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frame-wise logits as heatmap\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "sns.heatmap(frame_wise_logits.T, cmap=\"viridis\", annot=True, yticklabels=behaviours)\n",
    "plt.title(\"Frame-wise logits\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot framewise logits and video-level logits side by side\n",
    "fig, ax = plt.subplots(\n",
    "    1, 3, figsize=(20, 10), gridspec_kw={\"width_ratios\": [3, 0.75, 0.75]}\n",
    ")\n",
    "sns.heatmap(\n",
    "    frame_wise_logits.T, cmap=\"viridis\", annot=True, yticklabels=behaviours, ax=ax[0]\n",
    ")\n",
    "sns.heatmap(\n",
    "    video_level_logits.T,\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    ax=ax[1],\n",
    "    cbar=False,\n",
    ")\n",
    "sns.heatmap(\n",
    "    label.unsqueeze(0).numpy().T,\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    ax=ax[2],\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "ax[0].title.set_text(\"Masked Frame-wise Logits\")\n",
    "ax[1].title.set_text(\"Video-level Logits\")\n",
    "ax[2].title.set_text(\"Label\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subframe_features = framewise_features[0:8:,]\n",
    "\n",
    "# Subframe logits\n",
    "subframe_logits = []\n",
    "for feat in subframe_features:\n",
    "    subframe_logits.append(torch.sigmoid(classifier(feat).detach()).numpy())\n",
    "\n",
    "subframe_logits = np.array(subframe_logits)\n",
    "\n",
    "# Adaptive pool over subframe features\n",
    "subframe_features = subframe_features.unsqueeze(0)\n",
    "subframe_features = F.adaptive_avg_pool2d(subframe_features, (1, 2048))[0]\n",
    "\n",
    "# Apply classifier to subframe features\n",
    "subvideo_logits = torch.sigmoid(classifier(subframe_features)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot framewise logits and video-level logits side by side\n",
    "fig, ax = plt.subplots(\n",
    "    1, 4, figsize=(20, 10), gridspec_kw={\"width_ratios\": [3, 0.75, 0.75, 0.75]}\n",
    ")\n",
    "sns.heatmap(\n",
    "    subframe_logits.T, cmap=\"viridis\", annot=True, yticklabels=behaviours, ax=ax[0]\n",
    ")\n",
    "sns.heatmap(\n",
    "    subvideo_logits.T,\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    ax=ax[1],\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    video_level_logits.T,\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    ax=ax[2],\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "sns.heatmap(\n",
    "    label.unsqueeze(0).numpy().T,\n",
    "    cmap=\"viridis\",\n",
    "    annot=True,\n",
    "    ax=ax[3],\n",
    "    cbar=False,\n",
    ")\n",
    "\n",
    "ax[0].title.set_text(\"Masked Frame-wise Logits\")\n",
    "ax[1].title.set_text(\"Sub-video Logits\")\n",
    "ax[2].title.set_text(\"Video-level Logits\")\n",
    "ax[3].title.set_text(\"Label\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
