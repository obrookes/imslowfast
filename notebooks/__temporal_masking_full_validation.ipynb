{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl18206/anaconda3/envs/slowfast/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/dl18206/anaconda3/envs/slowfast/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import torch\n",
    "import scienceplots\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Slowfast imports\n",
    "from slowfast.models import build_model\n",
    "from slowfast.utils.parser import load_config, alt_parse_args\n",
    "from slowfast.datasets.loader import construct_loader\n",
    "\n",
    "from temporal_masking_utils import (\n",
    "    get_feature_map,\n",
    "    get_weighted_features,\n",
    "    extract_framewise_features,\n",
    "    calculate_masking_results,\n",
    ")\n",
    "from torchmetrics.functional.classification import multilabel_f1_score\n",
    "from torchmetrics.functional.classification import multilabel_average_precision\n",
    "from torchmetrics.functional.classification import multilabel_recall\n",
    "from torchmetrics.functional.classification import multilabel_precision\n",
    "\n",
    "\n",
    "plt.style.use(\"science\")\n",
    "plt.rcParams.update({\"font.family\": \"Times New Roman\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/train.csv\"\n",
    "val_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/annotations/standard/fg_only/standard/val.csv\"\n",
    "metadata_path = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/with_negative_pairing/new_metadata.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "\n",
    "train_df.columns = [\"subject_id\", \"label\"]\n",
    "val_df.columns = [\"subject_id\", \"label\"]\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "with open(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/behaviours.txt\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    behaviours = [beh.decode(\"utf-8\").strip() for beh in f.readlines()]\n",
    "\n",
    "with open(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/metadata/segments.txt\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    segments = [seg.decode(\"utf-8\").strip() for seg in f.readlines()]\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"value\"]], right_on=\"subject_id_fg\", left_on=\"subject_id\"\n",
    ")\n",
    "\n",
    "val_df = val_df.merge(\n",
    "    metadata[[\"subject_id_fg\", \"value\"]], right_on=\"subject_id_fg\", left_on=\"subject_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "path_to_config = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/configs/SLOW_8x8_R50_Local_TEST.yaml\"\n",
    "path_to_ckpt = \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/checkpoint_epoch_00100.pyth\"\n",
    "\n",
    "args = alt_parse_args()[:-1]\n",
    "cfg = load_config(\n",
    "    args[0],\n",
    "    path_to_config=path_to_config,\n",
    ")\n",
    "checkpoint = torch.load(path_to_ckpt, map_location=\"cpu\")\n",
    "\n",
    "model = build_model(cfg)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "model.cpu()\n",
    "\n",
    "classifier = model.head.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLING.BALANCED: False; BALANCE_TYPE: None\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "loader = construct_loader(cfg, \"test\")  # dataset = build_dataset(\"tap\", cfg, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, feat_maps, labels = [], [], []\n",
    "for i, (inputs, label, index, time, meta) in tqdm(enumerate(loader)):\n",
    "    # Get the feature map\n",
    "    feature_map = get_feature_map(model, inputs[0].squeeze())\n",
    "    names.append(meta[\"video_name\"])\n",
    "    feat_maps.append(feature_map.detach().cpu())\n",
    "    labels.append(label)\n",
    "\n",
    "    # Clear torch cache\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [name[0] for name in names]\n",
    "feat_maps = torch.cat(feat_maps, dim=0)\n",
    "labels = torch.cat(labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature maps to pickle\n",
    "with open(\n",
    "    \"/home/dl18206/Desktop/phd/code/personal/facebook/slowfast/dataset/results/r50_e100_fg_few_shot_train.pkl\",\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    torch.save(dict(names=names, feat_maps=feat_maps, labels=labels), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_thresh = 0.5\n",
    "mask_thresh = 0.5\n",
    "\n",
    "fg_names, bg_names, preds, weighted_preds, labels, masks = [], [], [], [], [], []\n",
    "\n",
    "for i, (inputs, label, index, time, meta) in tqdm(enumerate(loader)):\n",
    "    # Track names\n",
    "    fg_name = meta[\"fg_video_name\"][0]\n",
    "    bg_name = meta[\"bg_video_name\"][0]\n",
    "    fg_names.append(fg_name)\n",
    "    bg_names.append(bg_name)\n",
    "\n",
    "    # Extract feature map\n",
    "    fg_map = get_feature_map(model, inputs[\"fg_frames\"][0][0])\n",
    "    bg_map = get_feature_map(model, inputs[\"bg_frames\"][0][0])\n",
    "\n",
    "    # Get frame-wise features\n",
    "    fg_framewise_features = extract_framewise_features(fg_map)\n",
    "\n",
    "    # Get frame-wise logits\n",
    "    fg_framewise_logits = []\n",
    "    for feat in fg_framewise_features:\n",
    "        fg_framewise_logits.append(torch.sigmoid(classifier(feat).detach()).numpy())\n",
    "    fg_framewise_logits = np.array(fg_framewise_logits)\n",
    "\n",
    "    # Extract weighted features\n",
    "    weighted_features, non_weighted_features, mask = get_weighted_features(\n",
    "        fg_map,\n",
    "        bg_map,\n",
    "        classifier,\n",
    "        weight_thresh=weight_thresh,\n",
    "        mask_thresh=mask_thresh,\n",
    "        weight_features_by_mask=True,\n",
    "        return_mask=True,\n",
    "    )\n",
    "    # Store the mask\n",
    "    masks.append(mask)\n",
    "\n",
    "    # Apply the classifier\n",
    "    pred = torch.sigmoid(classifier(non_weighted_features).squeeze(0))\n",
    "    weighted_pred = torch.sigmoid(classifier(weighted_features).squeeze(0))\n",
    "\n",
    "    # Store the results\n",
    "    preds.append(pred.cpu().detach())\n",
    "    weighted_preds.append(weighted_pred.cpu().detach())\n",
    "    labels.append(label.cpu().detach())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} samples\")\n",
    "\n",
    "        # Convert to numpy\n",
    "        fg_names = np.array(fg_names)\n",
    "        bg_names = np.array(bg_names)\n",
    "\n",
    "        masks = np.array(masks)\n",
    "\n",
    "        preds = torch.stack(preds)\n",
    "        weighted_preds = torch.stack(weighted_preds)\n",
    "\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        # Save all in a single dictionary\n",
    "        results = {\n",
    "            \"fg_names\": fg_names,\n",
    "            \"bg_names\": bg_names,\n",
    "            \"preds\": preds,\n",
    "            \"weighted_preds\": weighted_preds,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "        }\n",
    "\n",
    "        # Save the results using torch\n",
    "        torch.save(\n",
    "            results,\n",
    "            f\"weighted_features_w-mask_weight_t={weight_thresh}_mask_thresh={mask_thresh}_iter={i}_split=val.pt\",\n",
    "        )\n",
    "\n",
    "        # Reset the lists\n",
    "        fg_names, bg_names, preds, weighted_preds, labels, masks = (\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "            [],\n",
    "        )\n",
    "\n",
    "        # Free up memory\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_names, bg_names, preds, weighted_preds, labels, masks = [], [], [], [], [], []\n",
    "\n",
    "iters = np.arange(0, 1100, 100)\n",
    "\n",
    "for iter in iters:\n",
    "    results = torch.load(\n",
    "        f\"weighted_features_w-mask_weight_t={weight_thresh}_mask_thresh={mask_thresh}_iter={iter}_split=val.pt\"\n",
    "    )\n",
    "\n",
    "    fg_names.append(results[\"fg_names\"])\n",
    "    bg_names.append(results[\"bg_names\"])\n",
    "    preds.append(results[\"preds\"])\n",
    "    weighted_preds.append(results[\"weighted_preds\"])\n",
    "    labels.append(results[\"labels\"])\n",
    "    masks.append(results[\"masks\"])\n",
    "\n",
    "# Concatenate the results\n",
    "fg_names = np.concatenate(fg_names)\n",
    "bg_names = np.concatenate(bg_names)\n",
    "masks = np.concatenate(masks)\n",
    "preds = torch.cat(preds)\n",
    "weighted_preds = torch.cat(weighted_preds)\n",
    "labels = torch.cat(labels)\n",
    "\n",
    "# Save the results\n",
    "results = {\n",
    "    \"fg_names\": fg_names,\n",
    "    \"bg_names\": bg_names,\n",
    "    \"preds\": preds,\n",
    "    \"weighted_preds\": weighted_preds,\n",
    "    \"labels\": labels,\n",
    "    \"masks\": masks,\n",
    "}\n",
    "\n",
    "torch.save(\n",
    "    results,\n",
    "    f\"weighted_features_w-mask_weight_t={weight_thresh}_mask_thresh={mask_thresh}_split=val.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted results\n",
    "weighted_result = torch.load(\n",
    "    \"weighted_features_w-mask_weight_t=0.5_mask_thresh=0.5_split=val.pt\"\n",
    ")\n",
    "\n",
    "recall = multilabel_recall(\n",
    "    weighted_result[\"preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "weighted_recall = multilabel_recall(\n",
    "    weighted_result[\"weighted_preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "f1 = multilabel_f1_score(\n",
    "    weighted_result[\"preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1).long(),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "weighted_f1 = multilabel_f1_score(\n",
    "    weighted_result[\"weighted_preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1).long(),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "average_precision = multilabel_precision(\n",
    "    weighted_result[\"preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1).long(),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "weighted_average_precision = multilabel_precision(\n",
    "    weighted_result[\"weighted_preds\"],\n",
    "    weighted_result[\"labels\"].squeeze(1).long(),\n",
    "    average=\"none\",\n",
    "    num_labels=14,\n",
    ")\n",
    "\n",
    "\n",
    "weighted_df = pd.DataFrame(\n",
    "    {\n",
    "        \"behaviour\": behaviours,\n",
    "        \"segment\": segments,\n",
    "        \"f1\": f1.cpu().numpy(),\n",
    "        \"weighted_f1\": weighted_f1.cpu().numpy(),\n",
    "        \"recall\": recall.cpu().numpy(),\n",
    "        \"weighted_recall\": weighted_recall.cpu().numpy(),\n",
    "        \"precision\": average_precision.cpu().numpy(),\n",
    "        \"weighted_precision\": weighted_average_precision.cpu().numpy(),\n",
    "    }\n",
    ")\n",
    "\n",
    "weighted_avg_df = pd.DataFrame(\n",
    "    {\n",
    "        \"overall\": weighted_df[weighted_df.columns[2:]].mean(),\n",
    "        \"head\": weighted_df[weighted_df.segment == \"head\"][\n",
    "            weighted_df.columns[2:]\n",
    "        ].mean(),\n",
    "        \"tail\": weighted_df[weighted_df.segment == \"tail\"][\n",
    "            weighted_df.columns[2:]\n",
    "        ].mean(),\n",
    "        \"fewshot\": weighted_df[weighted_df.segment == \"few_shot\"][\n",
    "            weighted_df.columns[2:]\n",
    "        ].mean(),\n",
    "    }\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_avg_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slowfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
